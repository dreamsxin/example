# 核密度估计 Kernel Density Estimation

概率密度估计方法用于估计一组数据集的概率密度分布，分为参数估计方法和非参数估计方法。

**参数估计方法**
假定样本集符合某一概率分布，然后根据样本集拟合该分布中的参数，例如：似然估计，混合高斯等，由于参数估计方法中需要加入主观的先验知识，往往很难拟合出与真实分布的模型；

**非参数估计法**
非参数估计并不加入任何先验知识，而是根据数据本身的特点、性质来拟合分布，这样能比参数估计方法得出更好的模型。核密度估计就是非参数估计中的一种。

核密度估计 KDE 由 Rosenblatt (1955) 和 Emanuel Parzen(1962) 提出，又名 Parzen window，设数据集包含 N 个样本，对这 N 个样本进行核函数拟合，将这 N 个概率密度函数进行叠加便得到了整个样本集的概率密度函数。

## 概率密度函数 Probability density function
一般使用高斯函数作为核函数。
> 将原始空间中的向量作为输入向量，并返回特征空间（转换后的数据空间,可能是高维）中向量的点积的函数称为核函数，可以认为核函数就是距离函数。

带宽 h 的选择：当选择极小的带宽值，每个点就是一个峰值，那么每个点就是一类，如果选择大的带宽值，那么所有的数据只有一个峰值，只有一类。

选择的高斯核，那么高斯核的方差，也就是h（也叫带宽，也叫窗口，我们这里说的邻域）应该选择多大呢？不同的带宽会导致最后的拟合结果差别很大。同时上面也提到过，理论上h->0的，但h太小，邻域中参与拟合的点就会过少。那么借助机器学习的理论，我们当然可以使用交叉验证选择最好的h。
另外，也有一个理论的推导给你选择h提供一些信息。 
在样本集给定的情况下，我们只能对样本点的概率密度进行计算，那拟合过后的概率密度应该和计算的值更加接近才好，基于这一点，我们定义一个误差函数，然后最小化该误差函数便能为h的选择提供一个大致的方向。选择最小化L2风险函数，即均平方积分误差函数(mean intergrated squared error)

如果带宽不是固定的，其变化取决于估计的位置（balloon estimator）或样本点（逐点估计pointwise estimator），由此可以产生一个非常强大的方法称为自适应或可变带宽核密度估计。

## Histogram

给定一个数据集，需要观察这些样本的分布情况，往往我们会采用直方图的方法来进行直观的展现。该直方图的特点是简单易懂，但缺点在于以下三个方面：（1）密度函数是不平滑的；（2）密度函数受子区间（即每个直方体）宽度影响很大，同样的原始数据如果取不同的子区间范围，那么展示的结果可能是完全不同的。（3）直方图最多只能展示2维数据，如果维度更多则无法有效展示。

直方图展示的分布曲线并不平滑，即在一个bin中的样本具有相等的概率密度，显然，这一点往往并不适合。解决这一问题的办法时增加bins的数量，当bins增到到样本的最大值时，就能对样本的每一点都会有一个属于自己的概率，但同时会带来其他问题，样本中没出现的值的概率为0，概率密度函数不连续，这同样存在很大的问题。如果我们将这些不连续的区间连续起来，那么这很大程度上便能符合我们的要求，其中一个思想就是对于样本中的某一点的概率密度，如果能把邻域的信息利用起来，那么最后的概率密度就会很大程度上改善不连续的问题。



