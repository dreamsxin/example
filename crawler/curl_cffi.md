curl_cffi å®Œæ•´é…ç½®æŒ‡å—ï¼šimpersonateã€TLSã€HTTP/2 æŒ‡çº¹å’Œä»£ç†è®¾ç½®

ä¸‹é¢æ˜¯ä¸€ä¸ªå®Œæ•´çš„ curl_cffi ä½¿ç”¨æŒ‡å—ï¼Œæ¶µç›– impersonate å‚æ•°ã€TLS/HTTP/2 æŒ‡çº¹æ¨¡æ‹Ÿä»¥åŠä»£ç†è®¾ç½®ã€‚

1. å®Œæ•´çš„ curl_cffi å®¢æˆ·ç«¯å®ç°

```python
# complete_curl_cffi_client.py
from curl_cffi import requests
import random
import time
import threading
from urllib.parse import urlparse
from fake_useragent import UserAgent
from user_agents import parse
import json

class CompleteCurlCffiClient:
    def __init__(self, 
                 proxy_url=None,
                 default_language="zh",
                 default_platform="windows", 
                 default_browser="chrome",
                 verify_ssl=False,
                 timeout=30,
                 max_retries=3):
        """
        å®Œæ•´çš„ curl_cffi å®¢æˆ·ç«¯
        
        å‚æ•°:
            proxy_url: ä»£ç†åœ°å€ (ä¾‹å¦‚: "http://127.0.0.1:8080")
            default_language: é»˜è®¤è¯­è¨€ (zh, en, mixed)
            default_platform: é»˜è®¤å¹³å° (windows, macos, linux, mobile, tablet)
            default_browser: é»˜è®¤æµè§ˆå™¨ (chrome, firefox, safari, edge, random)
            verify_ssl: æ˜¯å¦éªŒè¯ SSL è¯ä¹¦
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.proxy_url = proxy_url
        self.default_language = default_language
        self.default_platform = default_platform
        self.default_browser = default_browser
        self.verify_ssl = verify_ssl
        self.timeout = timeout
        self.max_retries = max_retries
        
        self.session_storage = {}
        self.lock = threading.Lock()
        
        # åˆå§‹åŒ– UA ç”Ÿæˆå™¨
        try:
            self.ua_generator = UserAgent()
            print("âœ“ fake-useragent åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ fake-useragent åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ua_generator = None
        
        # æµè§ˆå™¨ impersonate é…ç½®æ˜ å°„
        self.browser_impersonate_map = {
            'chrome': [
                "chrome110", "chrome107", "chrome104", "chrome101", 
                "chrome100", "chrome99", "chrome95", "chrome90"
            ],
            'firefox': [
                "firefox110", "firefox108", "firefox105", "firefox102",
                "firefox100", "firefox98", "firefox95"
            ],
            'safari': [
                "safari15_5", "safari15_3", "safari15_1", "safari14_1",
                "safari13_1", "safari12_1"
            ],
            'edge': [
                "edge99", "edge101", "edge95", "edge90"
            ]
        }
        
        # è¯­è¨€é…ç½®
        self.language_configs = {
            'zh': {
                'name': 'ä¸­æ–‡',
                'accept_language': self._generate_accept_language(['zh-CN', 'zh', 'en-US', 'en'], [1.0, 0.8, 0.6, 0.4]),
            },
            'en': {
                'name': 'è‹±æ–‡', 
                'accept_language': self._generate_accept_language(['en-US', 'en', 'zh-CN', 'zh'], [1.0, 0.9, 0.3, 0.2]),
            },
            'mixed': {
                'name': 'æ··åˆè¯­è¨€',
                'accept_language': self._generate_accept_language(['zh-CN', 'en-US', 'en', 'zh-TW', 'zh'], [1.0, 0.7, 0.6, 0.5, 0.4]),
            }
        }
        
        # å¹³å°é…ç½®
        self.platform_configs = {
            'windows': {
                'name': 'Windows',
                'sec_platform': '"Windows"'
            },
            'macos': {
                'name': 'macOS', 
                'sec_platform': '"macOS"'
            },
            'linux': {
                'name': 'Linux',
                'sec_platform': '"Linux"'
            },
            'mobile': {
                'name': 'ç§»åŠ¨è®¾å¤‡',
                'sec_platform': '"Android"'
            },
            'tablet': {
                'name': 'å¹³æ¿è®¾å¤‡', 
                'sec_platform': '"iPad"'
            }
        }
        
        print(f"curl_cffi å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
        if proxy_url:
            print(f"âœ“ ä»£ç†è®¾ç½®: {proxy_url}")
        print(f"âœ“ é»˜è®¤è¯­è¨€: {self.language_configs[default_language]['name']}")
        print(f"âœ“ é»˜è®¤å¹³å°: {self.platform_configs[default_platform]['name']}")
        print(f"âœ“ é»˜è®¤æµè§ˆå™¨: {default_browser}")
        print(f"âœ“ SSL éªŒè¯: {'å¼€å¯' if verify_ssl else 'å…³é—­'}")
    
    def _generate_accept_language(self, languages, weights):
        """ç”Ÿæˆ Accept-Language å¤´éƒ¨å€¼"""
        language_parts = []
        for i, lang in enumerate(languages):
            if i < len(weights):
                q = weights[i]
                language_parts.append(f"{lang};q={q:.1f}")
            else:
                language_parts.append(lang)
        
        if len(language_parts) > 1:
            secondary_langs = language_parts[1:]
            random.shuffle(secondary_langs)
            language_parts = [language_parts[0]] + secondary_langs
        
        return ', '.join(language_parts)
    
    def get_impersonate_target(self, browser_type, platform):
        """æ ¹æ®æµè§ˆå™¨ç±»å‹å’Œå¹³å°è·å– impersonate ç›®æ ‡"""
        if browser_type == "random":
            # éšæœºé€‰æ‹©æµè§ˆå™¨ç±»å‹
            browser_type = random.choice(list(self.browser_impersonate_map.keys()))
        
        if browser_type in self.browser_impersonate_map:
            targets = self.browser_impersonate_map[browser_type]
            return random.choice(targets)
        else:
            # é»˜è®¤ä½¿ç”¨ Chrome
            return random.choice(self.browser_impersonate_map['chrome'])
    
    def get_random_user_agent(self, platform=None, browser_type=None):
        """æ ¹æ®å¹³å°å’Œæµè§ˆå™¨ç±»å‹è·å–éšæœº User-Agent"""
        try:
            if self.ua_generator:
                if platform == "windows":
                    ua = self.ua_generator.windows
                elif platform == "macos":
                    ua = self.ua_generator.mac
                elif platform == "linux":
                    ua = self.ua_generator.linux
                elif platform in ["mobile", "tablet"]:
                    ua = self.ua_generator.mobile
                else:
                    ua = self.ua_generator.random
                
                # ç¡®ä¿ UA åŒ¹é…æµè§ˆå™¨ç±»å‹
                if browser_type and browser_type != "random":
                    max_attempts = 10
                    for _ in range(max_attempts):
                        if browser_type in ua.lower():
                            return ua
                        ua = self.ua_generator.random
                
                return ua
            else:
                return self._get_fallback_ua(platform, browser_type)
        except Exception as e:
            print(f"è·å– User-Agent å¤±è´¥: {e}")
            return self._get_fallback_ua(platform, browser_type)
    
    def _get_fallback_ua(self, platform, browser_type):
        """å¤‡ç”¨çš„ UA ç”Ÿæˆ"""
        base_ua = {
            'windows': {
                'chrome': "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
                'firefox': "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/119.0",
                'edge': "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0",
            },
            'macos': {
                'chrome': "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
                'firefox': "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/119.0",
                'safari': "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
            },
            'linux': {
                'chrome': "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
                'firefox': "Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/119.0"
            },
            'mobile': {
                'chrome': "Mozilla/5.0 (Linux; Android 10; SM-G973F) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Mobile Safari/537.36",
                'safari': "Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1"
            }
        }
        
        if platform not in base_ua:
            platform = 'windows'
        
        if browser_type and browser_type in base_ua[platform]:
            return base_ua[platform][browser_type]
        else:
            return list(base_ua[platform].values())[0]
    
    def parse_user_agent(self, user_agent_string):
        """è§£æ User-Agent å­—ç¬¦ä¸²"""
        try:
            ua = parse(user_agent_string)
            return {
                'browser_family': ua.browser.family.lower(),
                'browser_version': ua.browser.version_string,
                'os_family': ua.os.family.lower(),
                'os_version': ua.os.version_string,
                'is_mobile': ua.is_mobile,
                'is_tablet': ua.is_tablet,
                'is_pc': ua.is_pc,
                'device_family': ua.device.family.lower()
            }
        except Exception as e:
            ua_lower = user_agent_string.lower()
            return {
                'browser_family': 'chrome' if 'chrome' in ua_lower else 'firefox' if 'firefox' in ua_lower else 'safari' if 'safari' in ua_lower and 'chrome' not in ua_lower else 'edge' if 'edg' in ua_lower else 'chrome',
                'browser_version': '119.0',
                'os_family': 'windows' if 'windows' in ua_lower else 'mac' if 'mac' in ua_lower else 'linux' if 'linux' in ua_lower else 'windows',
                'os_version': '10',
                'is_mobile': any(x in ua_lower for x in ['mobile', 'android', 'iphone']),
                'is_tablet': any(x in ua_lower for x in ['tablet', 'ipad']),
                'is_pc': not any(x in ua_lower for x in ['mobile', 'android', 'iphone', 'tablet', 'ipad']),
                'device_family': 'other'
            }
    
    def generate_accept_header(self, ua_info):
        """ç”Ÿæˆ Accept å¤´éƒ¨"""
        browser_family = ua_info['browser_family'].lower()
        device_type = 'mobile' if ua_info['is_mobile'] else 'desktop'
        
        accept_configs = {
            'chrome': {
                'desktop': "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
                'mobile': "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7"
            },
            'firefox': {
                'desktop': "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
                'mobile': "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
            },
            'safari': {
                'desktop': "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                'mobile': "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
            },
            'edge': {
                'desktop': "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
                'mobile': "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7"
            }
        }
        
        if browser_family in accept_configs:
            return accept_configs[browser_family][device_type]
        else:
            return accept_configs['chrome'][device_type]
    
    def generate_accept_encoding_header(self, ua_info):
        """ç”Ÿæˆ Accept-Encoding å¤´éƒ¨"""
        browser_family = ua_info['browser_family'].lower()
        
        if browser_family in ['chrome', 'firefox', 'edge']:
            encodings = ['gzip', 'deflate', 'br', 'zstd']
        elif browser_family == 'safari':
            encodings = ['gzip', 'deflate', 'br']
        else:
            encodings = ['gzip', 'deflate', 'br']
        
        if ua_info['is_mobile'] and 'zstd' in encodings:
            encodings = [e for e in encodings if e != 'zstd']
        
        if random.random() > 0.3:
            base = encodings[0]
            others = encodings[1:]
            random.shuffle(others)
            encodings = [base] + others
        else:
            random.shuffle(encodings)
        
        return ', '.join(encodings)
    
    def get_session(self, session_id=None, language=None, platform=None, browser=None):
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        if session_id is None:
            session_id = threading.current_thread().ident
            
        language = language or self.default_language
        platform = platform or self.default_platform
        browser = browser or self.default_browser
        
        with self.lock:
            if session_id not in self.session_storage:
                # è·å– impersonate ç›®æ ‡
                impersonate_target = self.get_impersonate_target(browser, platform)
                
                # ç”Ÿæˆ User-Agent
                user_agent = self.get_random_user_agent(platform, browser)
                
                # è§£æ UA ä¿¡æ¯
                ua_info = self.parse_user_agent(user_agent)
                
                # ç”Ÿæˆå…¶ä»–å¤´éƒ¨
                accept = self.generate_accept_header(ua_info)
                accept_language = self.language_configs[language]['accept_language']
                accept_encoding = self.generate_accept_encoding_header(ua_info)
                
                # åˆ›å»º curl_cffi Session
                session = requests.Session()
                
                self.session_storage[session_id] = {
                    'session': session,
                    'impersonate_target': impersonate_target,
                    'user_agent': user_agent,
                    'language': language,
                    'platform': platform,
                    'browser': browser,
                    'ua_info': ua_info,
                    'headers': {
                        'User-Agent': user_agent,
                        'Accept': accept,
                        'Accept-Language': accept_language,
                        'Accept-Encoding': accept_encoding
                    },
                    'last_request_time': 0,
                    'request_count': 0,
                    'domain_cookies': {}
                }
                
                print(f"åˆ›å»ºä¼šè¯ {session_id}: "
                      f"{self.platform_configs[platform]['name']} - "
                      f"{browser} ({impersonate_target}) - "
                      f"{self.language_configs[language]['name']}")
                
            return self.session_storage[session_id]
    
    def generate_sec_headers(self, session_data):
        """ç”Ÿæˆå®‰å…¨ç›¸å…³å¤´éƒ¨"""
        ua_info = session_data['ua_info']
        platform = session_data['platform']
        
        try:
            major_version = ua_info['browser_version'].split('.')[0]
        except:
            major_version = "119"
        
        platform_header = self.platform_configs[platform]['sec_platform']
        browser_family = ua_info['browser_family']
        
        if browser_family == "chrome":
            return {
                "Sec-Ch-Ua": f'"Google Chrome";v="{major_version}", "Chromium";v="{major_version}", "Not?A_Brand";v="24"',
                "Sec-Ch-Ua-Mobile": "?0",
                "Sec-Ch-Ua-Platform": platform_header,
            }
        elif browser_family == "firefox":
            return {
                "Sec-Ch-Ua": f'"Not.A/Brand";v="8", "Chromium";v="{major_version}", "Google Chrome";v="{major_version}"',
                "Sec-Ch-Ua-Mobile": "?0", 
                "Sec-Ch-Ua-Platform": platform_header,
            }
        elif browser_family == "safari":
            return {
                "Sec-Ch-Ua": f'"Google Chrome";v="{major_version}", "Chromium";v="{major_version}", "Not?A_Brand";v="24"',
                "Sec-Ch-Ua-Mobile": "?0",
                "Sec-Ch-Ua-Platform": platform_header,
            }
        elif browser_family == "edge":
            return {
                "Sec-Ch-Ua": f'"Microsoft Edge";v="{major_version}", "Chromium";v="{major_version}", "Not?A_Brand";v="24"',
                "Sec-Ch-Ua-Mobile": "?0",
                "Sec-Ch-Ua-Platform": platform_header,
            }
        else:
            return {
                "Sec-Ch-Ua": f'"Google Chrome";v="{major_version}", "Chromium";v="{major_version}", "Not?A_Brand";v="24"',
                "Sec-Ch-Ua-Mobile": "?0",
                "Sec-Ch-Ua-Platform": platform_header,
            }
    
    def make_request(self, url, method="GET", headers=None, data=None, 
                    delay=True, session_id=None, language=None, 
                    platform=None, browser=None, retry_count=0):
        """å‘é€è¯·æ±‚"""
        session_data = self.get_session(session_id, language, platform, browser)
        session = session_data['session']
        impersonate_target = session_data['impersonate_target']
        
        # äººç±»åŒ–å»¶è¿Ÿ
        if delay and session_data['request_count'] > 0:
            current_time = time.time()
            time_since_last = current_time - session_data['last_request_time']
            min_delay = random.uniform(1, 3)
            if time_since_last < min_delay:
                sleep_time = min_delay - time_since_last + random.uniform(0.1, 0.5)
                time.sleep(sleep_time)
        
        # å‡†å¤‡è¯·æ±‚å¤´éƒ¨
        request_headers = session_data['headers'].copy()
        
        # æ·»åŠ å®‰å…¨å¤´éƒ¨
        sec_headers = self.generate_sec_headers(session_data)
        request_headers.update(sec_headers)
        
        # æ·»åŠ  Fetch å¤´éƒ¨
        fetch_headers = {
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1",
        }
        request_headers.update(fetch_headers)
        
        # æ·»åŠ å…¶ä»–å¤´éƒ¨
        request_headers["Upgrade-Insecure-Requests"] = "1"
        if random.random() > 0.5:
            request_headers["Dnt"] = "1"
        request_headers["Cache-Control"] = "max-age=0"
        
        # æ·»åŠ è‡ªå®šä¹‰å¤´éƒ¨
        if headers:
            request_headers.update(headers)
        
        # å‡†å¤‡ä»£ç†è®¾ç½®
        proxies = None
        if self.proxy_url:
            proxies = {
                'http': self.proxy_url,
                'https': self.proxy_url
            }
        
        # å‡†å¤‡è¯·æ±‚å‚æ•°
        request_kwargs = {
            'method': method,
            'url': url,
            'impersonate': impersonate_target,  # å…³é”®ï¼šè®¾ç½® TLS/HTTP2 æŒ‡çº¹æ¨¡æ‹Ÿ
            'headers': request_headers,
            'timeout': self.timeout,
            'verify': self.verify_ssl
        }
        
        # æ·»åŠ ä»£ç†è®¾ç½®
        if proxies:
            request_kwargs['proxies'] = proxies
        
        if data:
            if method.upper() in ['POST', 'PUT', 'PATCH']:
                if isinstance(data, (dict, list)):
                    request_kwargs['json'] = data
                else:
                    request_kwargs['data'] = data
        
        try:
            # å‘é€è¯·æ±‚
            start_time = time.time()
            response = session.request(**request_kwargs)
            response_time = time.time() - start_time
            
            # æ›´æ–°ä¼šè¯çŠ¶æ€
            with self.lock:
                session_data['last_request_time'] = time.time()
                session_data['request_count'] += 1
                
                # å­˜å‚¨åŸŸåcookies
                domain = urlparse(url).netloc
                if hasattr(response, 'cookies') and response.cookies:
                    session_data['domain_cookies'][domain] = dict(response.cookies)
            
            # è®°å½•è¯·æ±‚ä¿¡æ¯
            self.log_request(url, session_data, response.status_code, response_time)
            
            return response
            
        except Exception as e:
            print(f"è¯·æ±‚å¤±è´¥ ({retry_count + 1}/{self.max_retries + 1}): {e}")
            
            # é‡è¯•é€»è¾‘
            if retry_count < self.max_retries:
                wait_time = (2 ** retry_count) + random.uniform(0.1, 0.5)
                print(f"ç­‰å¾… {wait_time:.2f} ç§’åé‡è¯•...")
                time.sleep(wait_time)
                return self.make_request(
                    url, method, headers, data, delay, 
                    session_id, language, platform, browser, retry_count + 1
                )
            else:
                print(f"è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {url}")
                return None
    
    def log_request(self, url, session_data, status_code, response_time):
        """è®°å½•è¯·æ±‚ä¿¡æ¯"""
        domain = urlparse(url).netloc
        platform_name = self.platform_configs[session_data['platform']]['name']
        browser_name = session_data['browser']
        impersonate_target = session_data['impersonate_target']
        language_name = self.language_configs[session_data['language']]['name']
        
        status_color = "ğŸŸ¢" if status_code == 200 else "ğŸŸ¡" if status_code < 400 else "ğŸ”´"
        
        print(f"{status_color} [{platform_name} - {browser_name}({impersonate_target}) - {language_name}] "
              f"{domain} -> {status_code} ({response_time:.2f}s)")
    
    def get_session_info(self, session_id=None):
        """è·å–ä¼šè¯ä¿¡æ¯"""
        session_data = self.get_session(session_id)
        return {
            'session_id': session_id or threading.current_thread().ident,
            'platform': self.platform_configs[session_data['platform']]['name'],
            'browser': session_data['browser'],
            'impersonate_target': session_data['impersonate_target'],
            'language': self.language_configs[session_data['language']]['name'],
            'user_agent': session_data['user_agent'],
            'accept': session_data['headers']['Accept'],
            'accept_language': session_data['headers']['Accept-Language'],
            'accept_encoding': session_data['headers']['Accept-Encoding'],
            'request_count': session_data['request_count'],
            'proxy': self.proxy_url
        }
    
    def get_available_impersonate_targets(self):
        """è·å–å¯ç”¨çš„ impersonate ç›®æ ‡"""
        return self.browser_impersonate_map
    
    def close_session(self, session_id=None):
        """å…³é—­ä¼šè¯"""
        if session_id is None:
            session_id = threading.current_thread().ident
            
        with self.lock:
            if session_id in self.session_storage:
                # curl_cffi çš„ Session ä¸éœ€è¦æ˜¾å¼å…³é—­ï¼Œä½†æˆ‘ä»¬å¯ä»¥æ¸…ç†èµ„æº
                del self.session_storage[session_id]
                print(f"ä¼šè¯ {session_id} å·²å…³é—­")
    
    def close_all_sessions(self):
        """å…³é—­æ‰€æœ‰ä¼šè¯"""
        with self.lock:
            session_count = len(self.session_storage)
            self.session_storage.clear()
            print(f"æ‰€æœ‰ä¼šè¯å·²å…³é—­ (å…± {session_count} ä¸ª)")
```

2. é«˜çº§ä½¿ç”¨ç¤ºä¾‹

```python
# advanced_usage_examples.py
from complete_curl_cffi_client import CompleteCurlCffiClient
import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed

def demo_basic_usage():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    print("=== curl_cffi åŸºç¡€ä½¿ç”¨ç¤ºä¾‹ ===")
    
    # åˆ›å»ºä¸ä»£ç†çš„å®¢æˆ·ç«¯
    client = CompleteCurlCffiClient(
        proxy_url=None,  # ä¸ä½¿ç”¨ä»£ç†
        default_language="zh",
        default_platform="windows",
        default_browser="chrome",
        verify_ssl=False
    )
    
    # è·å–ä¼šè¯ä¿¡æ¯
    info = client.get_session_info()
    print(f"ä¼šè¯é…ç½®: {info['platform']} - {info['browser']}({info['impersonate_target']}) - {info['language']}")
    
    # å‘é€è¯·æ±‚
    response = client.make_request("https://httpbin.org/headers")
    if response and response.status_code == 200:
        print("è¯·æ±‚æˆåŠŸ!")
        headers = response.json()['headers']
        print(f"User-Agent: {headers.get('User-Agent', 'N/A')}")
    
    client.close_all_sessions()
    print()

def demo_with_proxy():
    """ä½¿ç”¨ä»£ç†ç¤ºä¾‹"""
    print("=== ä½¿ç”¨ä»£ç†ç¤ºä¾‹ ===")
    
    # åˆ›å»ºä½¿ç”¨ mitmproxy çš„å®¢æˆ·ç«¯
    client = CompleteCurlCffiClient(
        proxy_url="http://127.0.0.1:8080",  # mitmproxy ä»£ç†
        default_language="en",
        default_platform="macos", 
        default_browser="safari",
        verify_ssl=False  # ä½¿ç”¨ä»£ç†æ—¶éœ€è¦å…³é—­ SSL éªŒè¯
    )
    
    info = client.get_session_info()
    print(f"ä»£ç†é…ç½®: {info['proxy']}")
    print(f"ä¼šè¯é…ç½®: {info['platform']} - {info['browser']}({info['impersonate_target']}) - {info['language']}")
    
    response = client.make_request("https://httpbin.org/headers")
    if response and response.status_code == 200:
        print("é€šè¿‡ä»£ç†è¯·æ±‚æˆåŠŸ!")
    
    client.close_all_sessions()
    print()

def demo_different_browsers():
    """ä¸åŒæµè§ˆå™¨æŒ‡çº¹ç¤ºä¾‹"""
    print("=== ä¸åŒæµè§ˆå™¨æŒ‡çº¹ç¤ºä¾‹ ===")
    
    browsers = ['chrome', 'firefox', 'safari', 'edge']
    
    for browser in browsers:
        client = CompleteCurlCffiClient(
            default_browser=browser,
            verify_ssl=False
        )
        
        info = client.get_session_info()
        print(f"{browser.upper()}: impersonate={info['impersonate_target']}, UA={info['user_agent'][:50]}...")
        
        response = client.make_request("https://httpbin.org/user-agent")
        if response and response.status_code == 200:
            returned_ua = response.json().get('user-agent', 'N/A')
            print(f"  éªŒè¯: {returned_ua[:50]}...")
        
        client.close_all_sessions()
        time.sleep(1)
    
    print()

def demo_platform_specific():
    """å¹³å°ç‰¹å®šé…ç½®ç¤ºä¾‹"""
    print("=== å¹³å°ç‰¹å®šé…ç½®ç¤ºä¾‹ ===")
    
    platforms = ['windows', 'macos', 'linux', 'mobile']
    
    for platform in platforms:
        client = CompleteCurlCffiClient(
            default_platform=platform,
            default_browser="chrome",
            verify_ssl=False
        )
        
        info = client.get_session_info()
        print(f"{platform.upper()}: {info['user_agent'][:60]}...")
        
        client.close_all_sessions()
        time.sleep(0.5)
    
    print()

def demo_parallel_requests():
    """å¹¶è¡Œè¯·æ±‚ç¤ºä¾‹"""
    print("=== å¹¶è¡Œè¯·æ±‚ç¤ºä¾‹ ===")
    
    def worker(worker_id, client):
        """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
        # æ¯ä¸ªå·¥ä½œçº¿ç¨‹ä½¿ç”¨ä¸åŒçš„é…ç½®
        languages = ["zh", "en", "mixed"]
        platforms = ["windows", "macos", "linux"]
        browsers = ["chrome", "firefox", "safari", "edge"]
        
        language = random.choice(languages)
        platform = random.choice(platforms)
        browser = random.choice(browsers)
        
        session_info = client.get_session_info(worker_id)
        print(f"å·¥ä½œçº¿ç¨‹ {worker_id}: {session_info['platform']} - {session_info['browser']}({session_info['impersonate_target']}) - {session_info['language']}")
        
        response = client.make_request(
            "https://httpbin.org/headers",
            session_id=worker_id,
            language=language,
            platform=platform,
            browser=browser
        )
        
        if response and response.status_code == 200:
            return f"å·¥ä½œçº¿ç¨‹ {worker_id} æˆåŠŸ"
        else:
            return f"å·¥ä½œçº¿ç¨‹ {worker_id} å¤±è´¥"
    
    # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆä¸ä½¿ç”¨ä»£ç†ï¼‰
    client = CompleteCurlCffiClient(verify_ssl=False)
    
    # å¹¶è¡Œæ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=3) as executor:
        futures = [
            executor.submit(worker, i, client)
            for i in range(6)
        ]
        
        for future in as_completed(futures):
            result = future.result()
            print(result)
    
    client.close_all_sessions()
    print()

def demo_fingerprint_verification():
    """æŒ‡çº¹éªŒè¯ç¤ºä¾‹"""
    print("=== æŒ‡çº¹éªŒè¯ç¤ºä¾‹ ===")
    
    # æµ‹è¯•æŒ‡çº¹éªŒè¯ç½‘ç«™
    test_urls = [
        "https://tls.browserleaks.com/json",
        "https://httpbin.org/headers",
        "https://ja3er.com/json"
    ]
    
    client = CompleteCurlCffiClient(
        default_browser="chrome",
        verify_ssl=False
    )
    
    for url in test_urls:
        print(f"æµ‹è¯• {url}:")
        response = client.make_request(url)
        if response and response.status_code == 200:
            try:
                data = response.json()
                if "ja3" in data:
                    print(f"  JA3 æŒ‡çº¹: {data['ja3']}")
                if "akamai" in data:
                    print(f"  HTTP/2 æŒ‡çº¹: {data['akamai']}")
                if "headers" in data:
                    ua = data['headers'].get('User-Agent', 'N/A')
                    print(f"  User-Agent: {ua[:80]}...")
            except:
                print(f"  å“åº”: {response.text[:100]}...")
        else:
            print(f"  è¯·æ±‚å¤±è´¥: {response.status_code if response else 'æ— å“åº”'}")
        
        print()
        time.sleep(2)
    
    client.close_all_sessions()

if __name__ == "__main__":
    demo_basic_usage()
    demo_with_proxy()
    demo_different_browsers()
    demo_platform_specific()
    demo_parallel_requests()
    demo_fingerprint_verification()
```

3. é…ç½®ç®¡ç†å™¨

```python
# client_config_manager.py
import json
from complete_curl_cffi_client import CompleteCurlCffiClient

class ClientConfigManager:
    """å®¢æˆ·ç«¯é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_file="client_configs.json"):
        self.config_file = config_file
        self.configs = self.load_configs()
    
    def load_configs(self):
        """åŠ è½½é…ç½®"""
        default_configs = {
            'default_chinese': {
                'name': 'é»˜è®¤ä¸­æ–‡ç”¨æˆ·',
                'proxy_url': None,
                'language': 'zh',
                'platform': 'windows',
                'browser': 'chrome',
                'verify_ssl': False,
                'description': 'å…¸å‹çš„ä¸­æ–‡Windows Chromeç”¨æˆ·'
            },
            'english_mac_user': {
                'name': 'è‹±æ–‡Macç”¨æˆ·',
                'proxy_url': None, 
                'language': 'en',
                'platform': 'macos',
                'browser': 'safari',
                'verify_ssl': False,
                'description': 'å…¸å‹çš„è‹±æ–‡macOS Safariç”¨æˆ·'
            },
            'proxy_chinese': {
                'name': 'ä»£ç†ä¸­æ–‡ç”¨æˆ·',
                'proxy_url': 'http://127.0.0.1:8080',
                'language': 'zh',
                'platform': 'windows',
                'browser': 'chrome', 
                'verify_ssl': False,
                'description': 'ä½¿ç”¨ä»£ç†çš„ä¸­æ–‡Windowsç”¨æˆ·'
            },
            'mobile_user': {
                'name': 'ç§»åŠ¨ç”¨æˆ·',
                'proxy_url': None,
                'language': 'zh', 
                'platform': 'mobile',
                'browser': 'chrome',
                'verify_ssl': False,
                'description': 'ä¸­æ–‡ç§»åŠ¨ç”¨æˆ·'
            },
            'random_user': {
                'name': 'éšæœºç”¨æˆ·',
                'proxy_url': None,
                'language': 'random',
                'platform': 'random',
                'browser': 'random',
                'verify_ssl': False,
                'description': 'éšæœºé…ç½®çš„ç”¨æˆ·'
            }
        }
        
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return default_configs
    
    def save_configs(self):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.configs, f, indent=2, ensure_ascii=False)
        print(f"é…ç½®å·²ä¿å­˜åˆ° {self.config_file}")
    
    def create_client(self, config_name, **overrides):
        """æ ¹æ®é…ç½®åç§°åˆ›å»ºå®¢æˆ·ç«¯"""
        if config_name not in self.configs:
            raise ValueError(f"æœªçŸ¥çš„é…ç½®: {config_name}")
        
        config = self.configs[config_name].copy()
        config.update(overrides)  # åº”ç”¨è¦†ç›–å‚æ•°
        
        client = CompleteCurlCffiClient(
            proxy_url=config['proxy_url'],
            default_language=config['language'],
            default_platform=config['platform'],
            default_browser=config['browser'],
            verify_ssl=config['verify_ssl']
        )
        
        return client, config
    
    def list_configs(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨é…ç½®"""
        print("å¯ç”¨å®¢æˆ·ç«¯é…ç½®:")
        print("=" * 60)
        for config_name, config in self.configs.items():
            print(f"{config_name}:")
            print(f"  åç§°: {config['name']}")
            print(f"  æè¿°: {config['description']}")
            print(f"  ä»£ç†: {config['proxy_url'] or 'æ— '}")
            print(f"  è¯­è¨€: {config['language']}")
            print(f"  å¹³å°: {config['platform']}")
            print(f"  æµè§ˆå™¨: {config['browser']}")
            print(f"  SSLéªŒè¯: {'å¼€å¯' if config['verify_ssl'] else 'å…³é—­'}")
            print()
    
    def add_config(self, config_name, config_data):
        """æ·»åŠ æ–°é…ç½®"""
        self.configs[config_name] = config_data
        self.save_configs()
        print(f"é…ç½® '{config_name}' å·²æ·»åŠ ")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    manager = ClientConfigManager()
    manager.list_configs()
    
    # æµ‹è¯•ä¸åŒé…ç½®
    print("æµ‹è¯•ä¸åŒé…ç½®:")
    print("=" * 40)
    
    test_configs = ['default_chinese', 'english_mac_user', 'mobile_user']
    
    for config_name in test_configs:
        print(f"\næµ‹è¯•é…ç½®: {config_name}")
        client, config = manager.create_client(config_name)
        
        info = client.get_session_info()
        print(f"å®¢æˆ·ç«¯ä¿¡æ¯: {info['platform']} - {info['browser']}({info['impersonate_target']}) - {info['language']}")
        
        # æµ‹è¯•è¯·æ±‚
        response = client.make_request("https://httpbin.org/user-agent")
        if response and response.status_code == 200:
            print("è¯·æ±‚æˆåŠŸ!")
        
        client.close_all_sessions()
        time.sleep(1)
```

4. å®Œæ•´çš„ä½¿ç”¨æµç¨‹

å®‰è£…ä¾èµ–

```bash
pip install curl-cffi fake-useragent user-agents
```

åŸºç¡€ä½¿ç”¨

```python
from complete_curl_cffi_client import CompleteCurlCffiClient

# åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆä¸ä½¿ç”¨ä»£ç†ï¼‰
client = CompleteCurlCffiClient(
    proxy_url=None,
    default_language="zh", 
    default_platform="windows",
    default_browser="chrome",
    verify_ssl=False
)

# å‘é€è¯·æ±‚
response = client.make_request("https://httpbin.org/headers")
if response:
    print(response.json())

# å…³é—­ä¼šè¯
client.close_all_sessions()
```

ä½¿ç”¨ mitmproxy ä»£ç†

```python
# ä½¿ç”¨ mitmproxy ä»£ç†
client = CompleteCurlCffiClient(
    proxy_url="http://127.0.0.1:8080",  # mitmproxy åœ°å€
    verify_ssl=False  # å¿…é¡»å…³é—­ SSL éªŒè¯
)

response = client.make_request("https://httpbin.org/headers")
```

è‡ªå®šä¹‰ä¼šè¯é…ç½®

```python
# æŒ‰è¯·æ±‚è‡ªå®šä¹‰é…ç½®
response = client.make_request(
    "https://example.com",
    language="en",
    platform="macos", 
    browser="safari"
)
```

å…³é”®ç‰¹æ€§è¯´æ˜

1. impersonate å‚æ•°

Â· è‡ªåŠ¨æ ¹æ®æµè§ˆå™¨ç±»å‹é€‰æ‹©å¯¹åº”çš„ impersonate ç›®æ ‡
Â· æ”¯æŒ Chromeã€Firefoxã€Safariã€Edge ç­‰å¤šç§æµè§ˆå™¨
Â· æ¨¡æ‹ŸçœŸå®çš„ TLS å’Œ HTTP/2 æŒ‡çº¹

2. ä»£ç†æ”¯æŒ

Â· æ”¯æŒ HTTP/HTTPS ä»£ç†
Â· è‡ªåŠ¨é…ç½®ä»£ç†è®¾ç½®
Â· ä¸ mitmproxy å®Œç¾é…åˆ

3. æŒ‡çº¹æ¨¡æ‹Ÿ

Â· å®Œæ•´çš„æµè§ˆå™¨æŒ‡çº¹æ¨¡æ‹Ÿ
Â· è‡ªåŠ¨ç”ŸæˆåŒ¹é…çš„ User-Agentã€Acceptã€Accept-Language ç­‰å¤´éƒ¨
Â· æ”¯æŒå®‰å…¨å¤´éƒ¨ï¼ˆSec-*ï¼‰å’Œ Fetch å¤´éƒ¨

4. ä¼šè¯ç®¡ç†

Â· çº¿ç¨‹å®‰å…¨çš„ä¼šè¯ç®¡ç†
Â· æ¯ä¸ªä¼šè¯ä¿æŒä¸€è‡´çš„æŒ‡çº¹é…ç½®
Â· è‡ªåŠ¨ç»´æŠ¤ cookies å’Œä¼šè¯çŠ¶æ€

5. é”™è¯¯å¤„ç†å’Œé‡è¯•

Â· è‡ªåŠ¨é‡è¯•æœºåˆ¶
Â· æŒ‡æ•°é€€é¿ç­–ç•¥
Â· è¯¦ç»†çš„é”™è¯¯æ—¥å¿—

è¿™ä¸ªå®Œæ•´çš„ curl_cffi å®¢æˆ·ç«¯æä¾›äº†ä¼ä¸šçº§çš„æµè§ˆå™¨æŒ‡çº¹æ¨¡æ‹Ÿèƒ½åŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç»•è¿‡å¤§å¤šæ•°åçˆ¬ç³»ç»Ÿçš„æ£€æµ‹ã€‚

# ä¸ºä»€ä¹ˆ curl_cffi ä»æ— æ³•ç»•è¿‡éƒ¨åˆ†é«˜çº§åçˆ¬ç³»ç»Ÿ

å°½ç®¡ curl_cffi æä¾›äº†ä¼˜ç§€çš„ TLS å’Œ HTTP/2 æŒ‡çº¹æ¨¡æ‹Ÿèƒ½åŠ›ï¼Œä½†ä»ç„¶æœ‰ä¸€äº›ç½‘ç«™æ— æ³•ç»•è¿‡ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦åŸå› å’Œç›¸åº”çš„è§£å†³æ–¹æ¡ˆï¼š

1. JavaScript æŒ‘æˆ˜å’Œæµè§ˆå™¨ç¯å¢ƒæ£€æµ‹

é—®é¢˜åˆ†æ

è®¸å¤šé«˜çº§åçˆ¬ç³»ç»Ÿï¼ˆå¦‚ Cloudflare 5ç§’ç›¾ã€Datadomeã€Akamaiï¼‰ä¼šï¼š

Â· æ‰§è¡Œ JavaScript æŒ‘æˆ˜è®¡ç®—
Â· æ£€æµ‹æµè§ˆå™¨ API æ”¯æŒæƒ…å†µ
Â· éªŒè¯ DOM ç¯å¢ƒå’Œ WebGL æ¸²æŸ“
Â· æ£€æŸ¥å­—ä½“åˆ—è¡¨å’Œå±å¹•åˆ†è¾¨ç‡

è§£å†³æ–¹æ¡ˆ

```python
# ä½¿ç”¨ Playwright å¤„ç† JS æŒ‘æˆ˜
from playwright.sync_api import sync_playwright
import time

def bypass_js_challenge(url, proxy=None):
    with sync_playwright() as p:
        # å¯åŠ¨çœŸå®æµè§ˆå™¨
        browser = p.chromium.launch(
            headless=False,  # å¯è§†æ¨¡å¼æ›´å®¹æ˜“ç»•è¿‡æ£€æµ‹
            proxy=proxy
        )
        
        # åˆ›å»ºä¸Šä¸‹æ–‡ï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·
        context = browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
            locale="zh-CN",
            timezone_id="Asia/Shanghai"
        )
        
        page = context.new_page()
        
        # æ·»åŠ é¢å¤–çš„æŒ‡çº¹æ··æ·†
        page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
        """)
        
        try:
            page.goto(url, wait_until="networkidle", timeout=30000)
            
            # ç­‰å¾…å¯èƒ½çš„ JS æŒ‘æˆ˜
            time.sleep(5)
            
            # æ‰§è¡Œé¡µé¢å†…å®¹
            content = page.content()
            return content
            
        except Exception as e:
            print(f"JSæŒ‘æˆ˜ç»•è¿‡å¤±è´¥: {e}")
            return None
        finally:
            browser.close()
```

2. è¡Œä¸ºåˆ†æå’Œæœºå™¨å­¦ä¹ æ£€æµ‹

é—®é¢˜åˆ†æ

é«˜çº§ç³»ç»Ÿä¼šåˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼ï¼š

Â· é¼ æ ‡ç§»åŠ¨è½¨è¿¹
Â· ç‚¹å‡»æ¨¡å¼å’Œæ»šåŠ¨è¡Œä¸º
Â· è¯·æ±‚æ—¶é—´é—´éš”åˆ†å¸ƒ
Â· ä¼šè¯æŒç»­æ—¶é—´

è§£å†³æ–¹æ¡ˆ

```python
# é«˜çº§è¡Œä¸ºæ¨¡æ‹Ÿ
import random
import time
from selenium.webdriver.common.action_chains import ActionChains

class BehavioralSimulator:
    def __init__(self, driver):
        self.driver = driver
        self.actions = ActionChains(driver)
    
    def human_like_mouse_movement(self, element):
        """æ¨¡æ‹Ÿäººç±»é¼ æ ‡ç§»åŠ¨"""
        # è·å–å…ƒç´ ä½ç½®
        location = element.location
        size = element.size
        
        # ç”Ÿæˆéšæœºç§»åŠ¨è·¯å¾„
        moves = random.randint(3, 8)
        for i in range(moves):
            # éšæœºåç§»
            offset_x = random.randint(-50, 50)
            offset_y = random.randint(-50, 50)
            
            self.actions.move_by_offset(offset_x, offset_y)
            time.sleep(random.uniform(0.05, 0.2))
        
        # æœ€ç»ˆç§»åŠ¨åˆ°å…ƒç´ 
        self.actions.move_to_element(element)
        self.actions.perform()
    
    def random_delay(self, min_delay=1, max_delay=3):
        """éšæœºå»¶è¿Ÿ"""
        time.sleep(random.uniform(min_delay, max_delay))
    
    def human_typing(self, element, text):
        """æ¨¡æ‹Ÿäººç±»è¾“å…¥"""
        for char in text:
            element.send_keys(char)
            time.sleep(random.uniform(0.1, 0.3))
    
    def random_scroll(self):
        """éšæœºæ»šåŠ¨"""
        scroll_amount = random.randint(100, 500)
        if random.random() > 0.5:
            self.driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
        else:
            self.driver.execute_script(f"window.scrollBy(0, -{scroll_amount});")
        time.sleep(random.uniform(0.5, 2))
```

3. é«˜çº§ TLS æŒ‡çº¹æ£€æµ‹

é—®é¢˜åˆ†æ

æŸäº›ç³»ç»Ÿä¼šæ£€æµ‹ï¼š

Â· TLS å¯†ç å¥—ä»¶é¡ºåº
Â· TLS æ‰©å±•åˆ—è¡¨å’Œé¡ºåº
Â· ALPN åè®®åå•†
Â· è¯ä¹¦é€æ˜åº¦ä¿¡æ¯

è§£å†³æ–¹æ¡ˆ

```python
# ä½¿ç”¨æ›´åº•å±‚çš„ TLS é…ç½®
import ssl
import socket
from urllib3.util.ssl_ import create_urllib3_context

class AdvancedTLSConfig:
    @staticmethod
    def create_chrome_like_context():
        """åˆ›å»º Chrome ç±»ä¼¼çš„ TLS ä¸Šä¸‹æ–‡"""
        context = create_urllib3_context()
        
        # è®¾ç½® Chrome ç±»ä¼¼çš„å¯†ç å¥—ä»¶
        context.set_ciphers(
            'TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:'
            'TLS_CHACHA20_POLY1305_SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:'
            'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:'
            'ECDHE-RSA-AES256-GCM-SHA384'
        )
        
        # è®¾ç½® TLS æ‰©å±•
        context.set_alpn_protocols(['h2', 'http/1.1'])
        
        return context

# æˆ–è€…ä½¿ç”¨ specialized-tls åº“
try:
    from specialized_tls import ClientHello
    import asyncio
    
    async def advanced_tls_handshake():
        client_hello = ClientHello.imitate_chrome()
        # è‡ªå®šä¹‰ TLS æ¡æ‰‹è¿‡ç¨‹
        # ...
except ImportError:
    print("specialized-tls æœªå®‰è£…ï¼Œä½¿ç”¨æ ‡å‡† TLS")
```

4. IP ä¿¡èª‰å’Œè´¨é‡é—®é¢˜

é—®é¢˜åˆ†æ

Â· æ•°æ®ä¸­å¿ƒ IP è¢«æ ‡è®°
Â· ä»£ç† IP è¢«åˆ—å…¥é»‘åå•
Â· IP åœ°ç†ä½ç½®å¼‚å¸¸

è§£å†³æ–¹æ¡ˆ

```python
# IP è´¨é‡æ£€æµ‹å’Œè½®æ¢
import requests
from concurrent.futures import ThreadPoolExecutor

class IPQualityManager:
    def __init__(self, proxy_list):
        self.proxy_list = proxy_list
        self.verified_proxies = []
    
    def check_ip_quality(self, proxy):
        """æ£€æŸ¥ IP è´¨é‡"""
        test_urls = [
            "https://httpbin.org/ip",
            "https://api.ipify.org?format=json",
            "https://ipinfo.io/json"
        ]
        
        try:
            for url in test_urls:
                response = requests.get(
                    url, 
                    proxies={"http": proxy, "https": proxy},
                    timeout=10
                )
                if response.status_code != 200:
                    return False
            
            # æ£€æŸ¥ IP ç±»å‹
            ip_info = requests.get(
                "https://ipinfo.io/json",
                proxies={"http": proxy, "https": proxy},
                timeout=10
            ).json()
            
            # ä¼˜é€‰ä½å®… IP
            if any(tag in str(ip_info).lower() for tag in ['residential', 'isp', 'mobile']):
                return True
                
        except:
            return False
        
        return False
    
    def verify_proxies(self):
        """éªŒè¯ä»£ç†åˆ—è¡¨"""
        with ThreadPoolExecutor(max_workers=10) as executor:
            results = executor.map(self.check_ip_quality, self.proxy_list)
            
        self.verified_proxies = [
            proxy for proxy, is_valid in zip(self.proxy_list, results) 
            if is_valid
        ]
        
        print(f"éªŒè¯é€šè¿‡ {len(self.verified_proxies)}/{len(self.proxy_list)} ä¸ªä»£ç†")
        return self.verified_proxies
    
    def get_best_proxy(self):
        """è·å–æœ€ä½³ä»£ç†"""
        if not self.verified_proxies:
            self.verify_proxies()
        
        return random.choice(self.verified_proxies) if self.verified_proxies else None
```

5. é«˜çº§ HTTP/2 æŒ‡çº¹æ£€æµ‹

é—®é¢˜åˆ†æ

æ£€æµ‹ï¼š

Â· SETTINGS å¸§çš„ç²¾ç¡®é¡ºåºå’Œå€¼
Â· WINDOW_UPDATE å¸§çš„æ—¶æœº
Â· HEADERS å¸§çš„å‹ç¼©ç®—æ³•ä½¿ç”¨
Â· æµä¼˜å…ˆçº§å’Œä¾èµ–å…³ç³»

è§£å†³æ–¹æ¡ˆ

```python
# ä½¿ç”¨ä¸“é—¨çš„ä½çº§ HTTP/2 åº“
import h2.connection
import h2.config

class AdvancedHTTP2Client:
    def __init__(self):
        config = h2.config.H2Configuration(
            client_side=True,
            header_encoding='utf-8'
        )
        self.conn = h2.connection.H2Connection(config=config)
    
    def simulate_chrome_h2(self):
        """æ¨¡æ‹Ÿ Chrome çš„ HTTP/2 è¡Œä¸º"""
        # Chrome ç‰¹å®šçš„ SETTINGS
        chrome_settings = {
            h2.settings.SettingCodes.HEADER_TABLE_SIZE: 65536,
            h2.settings.SettingCodes.MAX_CONCURRENT_STREAMS: 1000,
            h2.settings.SettingCodes.INITIAL_WINDOW_SIZE: 6291456,
            h2.settings.SettingCodes.MAX_FRAME_SIZE: 16384,
            h2.settings.SettingCodes.MAX_HEADER_LIST_SIZE: 262144,
        }
        
        self.conn.local_settings.update(chrome_settings)
        self.conn.remote_settings.update(chrome_settings)
        
        return self.conn
```

6. Canvas å’Œ WebGL æŒ‡çº¹

é—®é¢˜åˆ†æ

ç½‘ç«™é€šè¿‡ Canvas ç»˜å›¾æ£€æµ‹ç¡¬ä»¶å’Œæµè§ˆå™¨å·®å¼‚ã€‚

è§£å†³æ–¹æ¡ˆ

```python
# ä½¿ç”¨ Playwright ä¿®æ”¹ Canvas æŒ‡çº¹
from playwright.sync_api import sync_playwright

def modify_canvas_fingerprint(page):
    """ä¿®æ”¹ Canvas æŒ‡çº¹"""
    page.add_init_script("""
        // è¦†ç›– Canvas æ–¹æ³•
        const originalGetImageData = CanvasRenderingContext2D.prototype.getImageData;
        CanvasRenderingContext2D.prototype.getImageData = function(...args) {
            const result = originalGetImageData.apply(this, args);
            // æ·»åŠ å¾®å°éšæœºå™ªå£°
            for (let i = 0; i < result.data.length; i += 4) {
                result.data[i] = result.data[i] + Math.random() * 0.01;
            }
            return result;
        };
        
        // è¦†ç›– WebGL æ–¹æ³•
        const originalGetParameter = WebGLRenderingContext.prototype.getParameter;
        WebGLRenderingContext.prototype.getParameter = function(parameter) {
            const result = originalGetParameter.call(this, parameter);
            
            // ä¿®æ”¹ç‰¹å®šå‚æ•°
            if (parameter === this.VERSION) {
                return "WebGL 1.0 (OpenGL ES 2.0 Chromium)";
            }
            if (parameter === this.SHADING_LANGUAGE_VERSION) {
                return "WebGL GLSL ES 1.0 (OpenGL ES GLSL ES 1.0 Chromium)";
            }
            
            return result;
        };
    """)
```

7. ç»¼åˆè§£å†³æ–¹æ¡ˆï¼šæ··åˆæ–¹æ³•

```python
# ç»¼åˆç»•è¿‡æ–¹æ¡ˆ
class AdvancedBypassSystem:
    def __init__(self):
        self.proxy_manager = IPQualityManager([])
        self.current_strategy = "curl_cffi"
    
    def try_bypass(self, url, max_retries=3):
        """å°è¯•å¤šç§ç»•è¿‡æ–¹æ³•"""
        strategies = [
            self._curl_cffi_approach,
            self._playwright_approach,
            self._selenium_approach,
            self._manual_approach
        ]
        
        for attempt in range(max_retries):
            for strategy in strategies:
                print(f"å°è¯•ç­–ç•¥: {strategy.__name__}, ç¬¬ {attempt + 1} æ¬¡å°è¯•")
                
                try:
                    result = strategy(url)
                    if result:
                        print(f"æˆåŠŸä½¿ç”¨ {strategy.__name__}")
                        return result
                except Exception as e:
                    print(f"ç­–ç•¥ {strategy.__name__} å¤±è´¥: {e}")
                    continue
            
            # æ›´æ¢ä»£ç†
            new_proxy = self.proxy_manager.get_best_proxy()
            print(f"æ›´æ¢ä»£ç†: {new_proxy}")
            
            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        
        return None
    
    def _curl_cffi_approach(self, url):
        """curl_cffi æ–¹æ³•"""
        from curl_cffi import requests
        
        response = requests.get(
            url,
            impersonate="chrome110",
            timeout=30
        )
        
        if response.status_code == 200:
            # æ£€æŸ¥æ˜¯å¦è¢«æŒ‘æˆ˜
            if "challenge" in response.text.lower() or "cloudflare" in response.text.lower():
                raise Exception("è§¦å‘æŒ‘æˆ˜é¡µé¢")
            return response.text
        
        raise Exception(f"HTTP {response.status_code}")
    
    def _playwright_approach(self, url):
        """Playwright æ–¹æ³•"""
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            context = browser.new_context()
            page = context.new_page()
            
            # è®¾ç½®é«˜çº§æŒ‡çº¹æ··æ·†
            self._setup_advanced_fingerprinting(page)
            
            page.goto(url, wait_until="networkidle")
            
            # å¤„ç†å¯èƒ½çš„æŒ‘æˆ˜
            if self._handle_challenges(page):
                content = page.content()
                browser.close()
                return content
            
            browser.close()
            raise Exception("Playwright æ–¹æ³•å¤±è´¥")
    
    def _selenium_approach(self, url):
        """Selenium æ–¹æ³•"""
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        
        options = Options()
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        driver = webdriver.Chrome(options=options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        try:
            driver.get(url)
            # æ·»åŠ è¡Œä¸ºæ¨¡æ‹Ÿ
            behavioral_sim = BehavioralSimulator(driver)
            behavioral_sim.random_delay(2, 5)
            behavioral_sim.random_scroll()
            
            return driver.page_source
        finally:
            driver.quit()
    
    def _manual_approach(self, url):
        """æ‰‹åŠ¨åˆ†ææ–¹æ³•"""
        # åˆ†æé¡µé¢ï¼Œæ‰‹åŠ¨æå–æ•°æ®
        # ä½¿ç”¨å¤šä¸ªæ¥æºç»„åˆä¿¡æ¯
        # è°ƒç”¨å®˜æ–¹ APIï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        pass
    
    def _setup_advanced_fingerprinting(self, page):
        """è®¾ç½®é«˜çº§æŒ‡çº¹æ··æ·†"""
        page.add_init_script("""
            // ä¿®æ”¹å„ç§æŒ‡çº¹å±æ€§
            Object.defineProperty(navigator, 'platform', {
                get: () => 'Win32'
            });
            
            Object.defineProperty(navigator, 'hardwareConcurrency', {
                get: () => 8
            });
            
            Object.defineProperty(navigator, 'deviceMemory', {
                get: () => 8
            });
            
            // ä¿®æ”¹æ’ä»¶åˆ—è¡¨
            Object.defineProperty(navigator, 'plugins', {
                get: () => [
                    {name: 'Chrome PDF Plugin'}, 
                    {name: 'Chrome PDF Viewer'},
                    {name: 'Native Client'}
                ]
            });
        """)
    
    def _handle_challenges(self, page):
        """å¤„ç†æŒ‘æˆ˜é¡µé¢"""
        # æ£€æµ‹æŒ‘æˆ˜ç±»å‹å¹¶ç›¸åº”å¤„ç†
        challenge_selectors = [
            '#challenge-form',
            '.challenge-form',
            '[data-ray]',
            '.cf-browser-verification'
        ]
        
        for selector in challenge_selectors:
            if page.query_selector(selector):
                print("æ£€æµ‹åˆ°æŒ‘æˆ˜é¡µé¢ï¼Œå°è¯•è‡ªåŠ¨å¤„ç†...")
                # ç­‰å¾…æŒ‘æˆ˜å®Œæˆæˆ–æ‰‹åŠ¨å¤„ç†
                page.wait_for_timeout(10000)
                return True
        
        return False
```

8. é’ˆå¯¹ç‰¹å®šåçˆ¬ç³»ç»Ÿçš„ä¸“é—¨æ–¹æ¡ˆ

Cloudflare 5ç§’ç›¾

```python
def bypass_cloudflare(url):
    """ä¸“é—¨ç»•è¿‡ Cloudflare"""
    from cloudscraper import create_scraper
    
    scraper = create_scraper(
        browser={
            'browser': 'chrome',
            'platform': 'windows',
            'mobile': False
        }
    )
    
    try:
        response = scraper.get(url, timeout=30)
        return response.text
    except Exception as e:
        print(f"Cloudflare ç»•è¿‡å¤±è´¥: {e}")
        return None
```

Datadome ä¿æŠ¤

```python
def bypass_datadome(url):
    """ä¸“é—¨ç»•è¿‡ Datadome"""
    # Datadome éœ€è¦æ›´å¤æ‚çš„ JS æ‰§è¡Œç¯å¢ƒ
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    
    options = Options()
    options.add_argument("--disable-blink-features=AutomationControlled")
    
    driver = webdriver.Chrome(options=options)
    
    try:
        driver.get(url)
        
        # ç­‰å¾…å¯èƒ½çš„åçˆ¬å¤„ç†
        import time
        time.sleep(10)
        
        # æ£€æŸ¥æ˜¯å¦è¢«æ‹¦æˆª
        if "access denied" in driver.page_source.lower():
            print("è¢« Datadome æ‹¦æˆª")
            return None
        
        return driver.page_source
    finally:
        driver.quit()
```

æ€»ç»“

æ— æ³•ç»•è¿‡çš„åŸå› ä¸»è¦åŒ…æ‹¬ï¼š

1. JavaScript æ‰§è¡Œè¦æ±‚ - éœ€è¦çœŸå®æµè§ˆå™¨ç¯å¢ƒ
2. è¡Œä¸ºåˆ†æ - éœ€è¦æ¨¡æ‹Ÿäººç±»äº¤äº’æ¨¡å¼
3. é«˜çº§æŒ‡çº¹æ£€æµ‹ - éœ€è¦æ›´åº•å±‚çš„åè®®æ§åˆ¶
4. IP è´¨é‡ - éœ€è¦é«˜è´¨é‡çš„ä½å®…ä»£ç†
5. æœºå™¨å­¦ä¹ æ¨¡å‹ - éœ€è¦ä¸æ–­æ›´æ–°çš„å¯¹æŠ—ç­–ç•¥

è§£å†³æ–¹æ¡ˆï¼š

Â· ç»„åˆä½¿ç”¨å¤šç§å·¥å…·ï¼ˆcurl_cffi + Playwright + Seleniumï¼‰
Â· ä½¿ç”¨ä¸“ä¸šåçˆ¬æœåŠ¡ï¼ˆå¦‚ ScrapingBeeã€ScraperAPIï¼‰
Â· äººå·¥åˆ†æç›®æ ‡ç½‘ç«™çš„å…·ä½“é˜²æŠ¤æœºåˆ¶
Â· æŒç»­æ›´æ–°æŒ‡çº¹å’Œç­–ç•¥

å¯¹äºæœ€ä¸¥æ ¼çš„é˜²æŠ¤ï¼Œé€šå¸¸éœ€è¦ç»“åˆå¤šç§æŠ€æœ¯æ‰‹æ®µï¼Œå¹¶ä¸”å¯èƒ½éœ€è¦äººå·¥å¹²é¢„æˆ–ä½¿ç”¨å•†ä¸šåçˆ¬æœåŠ¡ã€‚