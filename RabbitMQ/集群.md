## 使用 Nginx 做负载均衡
```conf
#在http外添加如下配置
stream {
    upstream rabbitmqtt {
        server 192.168.1.17:1883;
        server 192.168.1.18:1883;
        server 192.168.1.19:1883;
    }

    server {
        listen       1884 so_keepalive=on;
        proxy_connect_timeout 60s;
        proxy_timeout 60s;
        proxy_pass rabbitmqtt;
        tcp_nodelay on;
    }
}
```
## 默认的集群模式

比如有节点 node1和node2、node3，三个节点是普通集群，但是他们仅有相同的元数据,即交换机、队列的结构；
​
案例：
消息只存在其中的一个节点里面，假如消息A，存储在node1节点，
消费者连接node1个节点消费消息时，可以直接取出来；
​
但如果 消费者是连接的是其他节点
那rabbitmq会把 queue 中的消息从存储它的节点中取出，并经过连接节点转发后再发送给消费者
​
问题：
假如node1故障，那node2无法获取node1存储未被消费的消息；
如果node1持久化后故障，那需要等node1恢复后才可以正常消费
如果ndoe1没做持久化后故障，那消息将会丢失
​
这个情况无法实现高可用性，且节点间会增加通讯获取消息，性能存在瓶颈
​
项目中springboot+amqp里面需要写多个节点的配置，比如下面
​
spring.rabbitmq.addresses = 192.168.1.1:5672,192.168.1.2:5672,192.168.1.3:5672
​
该模式更适合于消息无需持久化的场景，如日志传输的队列

## 队列做成镜像队列

让各队列存在于多个节点中
和普通集群比较大的区别就是【队列queue的消息message 】会在集群各节点之间同步，且并不是在 consumer 获取数据时临时拉取，而普通集群则是临时从存储的节点里面拉取对应的数据
​​
结论：
实现了高可用性，部分节点挂掉后，不影响正常的消费
可以保证100%消息不丢失，推荐3个奇数节点，结合LVS+Keepalive进行IP漂移，防止单点故障
​
缺点：由于镜像队列模式下，消息数量过多，大量的消息同步也会加大网络带宽开销，适合高可用要求比较高的项目
过多节点的话，性能则更加受影响
```shell
## #节点一，主节点,创建-v映射目录
docker run -d --hostname rabbit_host1 --name rabbitmq1 -p 15672:15672 -p 5672:5672 -e RABBITMQ_NODENAME=rabbit -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=xdclass.net168  -e RABBITMQ_ERLANG_COOKIE='rabbitmq_cookie_xdclass' --privileged=true -v /usr/local/rabbitmq/1/lib:/var/lib/rabbitmq -v /usr/local/rabbitmq/1/log:/var/log/rabbitmq rabbitmq:management
​
#节点二,创建-v映射目录
docker run -d --hostname rabbit_host2 --name rabbitmq2  -p 15673:15672 -p 5673:5672 --link rabbitmq1:rabbit_host1 -e RABBITMQ_NODENAME=rabbit -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=xdclass.net168 -e RABBITMQ_ERLANG_COOKIE='rabbitmq_cookie_xdclass' --privileged=true -v /usr/local/rabbitmq/2/lib:/var/lib/rabbitmq -v /usr/local/rabbitmq/2/log:/var/log/rabbitmq rabbitmq:management
​
#节点三,创建-v映射目录
docker run -d --hostname rabbit_host3 --name rabbitmq3 -p 15674:15672 -p 5674:5672 --link rabbitmq1:rabbit_host1 --link rabbitmq2:rabbit_host2 -e RABBITMQ_NODENAME=rabbit -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=xdclass.net168 -e RABBITMQ_ERLANG_COOKIE='rabbitmq_cookie_xdclass' --privileged=true -v /usr/local/rabbitmq/3/lib:/var/lib/rabbitmq -v /usr/local/rabbitmq/3/log:/var/log/rabbitmq rabbitmq:management
```

- --hostname 自定义Docker容器的 hostname
​
- --link 容器之间连接,link不可或缺，使得三个容器能互相通信
​
- --privileged=true 使用该参数，container内的root拥有真正的root权限，否则容器出现permission denied
​
- -v 宿主机和容器路径映射
​
参数 RABBITMQ_NODENAME，缺省 Unix*: rabbit@$HOSTNAME
参数 RABBITMQ_DEFAULT_USER=admin
参数 RABBITMQ_DEFAULT_PASS=xdclass.net168
​
Erlang Cookie 值必须相同，也就是一个集群内 RABBITMQ_ERLANG_COOKIE 参数的值必须相同， 相当于不同节点之间通讯的密钥，erlang.cookie是erlang的分布式token文件，集群内各个节点的erlang.cookie需要相同，才可以互相通信

### 配置集群

```shell
节点一配置集群
docker exec -it rabbitmq1 bash
rabbitmqctl stop_app
rabbitmqctl reset
rabbitmqctl start_app
exit
​
​
节点二加入集群，--ram是以内存方式加入,忽略该参数默认为磁盘节点。
docker exec -it rabbitmq2 bash
rabbitmqctl stop_app
rabbitmqctl join_cluster --ram rabbit@rabbit_host1
rabbitmqctl start_app
exit
​
​
节点三加入集群，--ram是以内存方式加入,忽略该参数默认为磁盘节点。
​
docker exec -it rabbitmq3 bash
rabbitmqctl stop_app
rabbitmqctl reset
rabbitmqctl join_cluster --ram rabbit@rabbit_host1
rabbitmqctl start_app
exit
​
#查看集群节点状态,配置启动了3个节点，1个磁盘节点和2个内存节点
​
rabbitmqctl cluster_status
```

