

## 方式1：使用 toStartOfHour 函数

```sql
SELECT
    toStartOfHour(created_at) AS hour_time,
    sumIf(1, status = 1) AS success_count,
    sumIf(1, status = 0) AS fail_count,
    success_count + fail_count AS total_count,
    round(success_count / total_count * 100, 2) AS success_rate
FROM search_log
WHERE created_at >= '2024-01-01 00:00:00'  -- 根据需要调整时间范围
GROUP BY hour_time
ORDER BY hour_time
```

## 方式2：使用 date_trunc 函数

```sql
SELECT
    date_trunc('hour', created_at) AS hour_time,
    countIf(status = 1) AS success_count,
    countIf(status = 0) AS fail_count,
    count() AS total_count
FROM search_log
WHERE created_at >= now() - INTERVAL 1 DAY  -- 最近24小时
GROUP BY hour_time
ORDER BY hour_time
```

## 方式3：使用 CASE WHEN 语句

```sql
SELECT
    toStartOfHour(created_at) AS hour_time,
    count(CASE WHEN status = 1 THEN 1 END) AS success_count,
    count(CASE WHEN status = 0 THEN 1 END) AS fail_count,
    count(*) AS total_count
FROM search_log
WHERE created_at >= today()  -- 今天的数据
GROUP BY hour_time
ORDER BY hour_time
```

## 方式4：包含更多统计信息

```sql
SELECT
    toStartOfHour(created_at) AS hour_time,
    -- 数量统计
    countIf(status = 1) AS success_count,
    countIf(status = 0) AS fail_count,
    count() AS total_count,
    -- 成功率
    round(countIf(status = 1) / count() * 100, 2) AS success_rate_pct,
    -- 平均耗时（仅成功请求）
    round(avgIf(used_time, status = 1), 2) AS avg_used_time_success,
    -- 用户数
    uniqExact(user_id) AS unique_users
FROM search_log
WHERE created_at >= now() - INTERVAL 7 DAY  -- 最近7天
GROUP BY hour_time
ORDER BY hour_time DESC
```

## 按小时和地区双重分组

```sql
SELECT
    toStartOfHour(created_at) AS hour_time,
    region,
    countIf(status = 1) AS success_count,
    countIf(status = 0) AS fail_count,
    count() AS total_count
FROM search_log
WHERE created_at >= now() - INTERVAL 1 DAY
GROUP BY hour_time, region
ORDER BY hour_time DESC, total_count DESC
```

## 性能优化建议

1. **添加时间条件**：务必在 WHERE 子句中指定时间范围，利用分区裁剪
2. **使用物化视图**：如果频繁查询，可以创建物化视图

```sql
-- 创建物化视图预聚合数据
CREATE MATERIALIZED VIEW search_log_hourly_mv
ENGINE = AggregatingMergeTree()
PARTITION BY toYYYYMM(hour_time)
ORDER BY (hour_time, region)
AS SELECT
    toStartOfHour(created_at) AS hour_time,
    region,
    countIfState(status = 1) AS success_count,
    countIfState(status = 0) AS fail_count
FROM search_log
GROUP BY hour_time, region
```

选择哪种方式取决于您的具体需求：
- 方式1和2适合基础统计
- 方式3更符合SQL标准
- 方式4提供更全面的分析维度

--------------------------------------------

统计一分钟内的P50、P70、P90、P95、P99以及最小和最大延迟，可以使用以下ClickHouse查询：

## 基本延迟统计查询

```sql
SELECT
    toStartOfMinute(created_at) as time_minute,
    count(*) as request_count,
    min(used_time) as min_latency,
    max(used_time) as max_latency,
    quantile(0.50)(used_time) as p50_latency,
    quantile(0.70)(used_time) as p70_latency,
    quantile(0.90)(used_time) as p90_latency,
    quantile(0.95)(used_time) as p95_latency,
    quantile(0.99)(used_time) as p99_latency,
    avg(used_time) as avg_latency
FROM default.search_log
WHERE created_at >= now() - INTERVAL 1 HOUR  -- 最近1小时的数据
GROUP BY time_minute
ORDER BY time_minute DESC
LIMIT 100;
```

## 更详细的分钟级延迟监控

```sql
SELECT
    toStartOfMinute(created_at) as time_minute,
    count(*) as total_requests,
    -- 最小/最大延迟
    min(used_time) as min_latency,
    max(used_time) as max_latency,
    -- 分位数延迟
    quantile(0.50)(used_time) as p50,
    quantile(0.70)(used_time) as p70,
    quantile(0.80)(used_time) as p80,
    quantile(0.90)(used_time) as p90,
    quantile(0.95)(used_time) as p95,
    quantile(0.99)(used_time) as p99,
    quantile(0.999)(used_time) as p999,
    -- 平均延迟和标准差
    avg(used_time) as avg_latency,
    stddevPop(used_time) as std_latency,
    -- 错误率
    countIf(err_code != 0) as error_count,
    round(100 * error_count / total_requests, 2) as error_rate_percent
FROM default.search_log
WHERE created_at >= now() - INTERVAL 1 HOUR
GROUP BY time_minute
ORDER BY time_minute DESC;
```

## 按错误码分组的分钟级延迟

```sql
SELECT
    toStartOfMinute(created_at) as time_minute,
    err_code,
    count(*) as request_count,
    min(used_time) as min_latency,
    max(used_time) as max_latency,
    quantile(0.50)(used_time) as p50,
    quantile(0.90)(used_time) as p90,
    quantile(0.95)(used_time) as p95,
    quantile(0.99)(used_time) as p99,
    avg(used_time) as avg_latency
FROM default.search_log
WHERE created_at >= now() - INTERVAL 1 HOUR
GROUP BY time_minute, err_code
HAVING request_count > 0
ORDER BY time_minute DESC, err_code;
```

## 实时监控视图（最近10分钟）

```sql
SELECT
    time_minute,
    total_requests,
    min_latency,
    max_latency,
    p50,
    p90,
    p95,
    p99,
    avg_latency,
    -- 延迟趋势（与上一分钟比较）
    lag(avg_latency) OVER (ORDER BY time_minute) as prev_avg_latency,
    round(avg_latency - prev_avg_latency, 2) as avg_latency_diff
FROM (
    SELECT
        toStartOfMinute(created_at) as time_minute,
        count(*) as total_requests,
        min(used_time) as min_latency,
        max(used_time) as max_latency,
        quantile(0.50)(used_time) as p50,
        quantile(0.90)(used_time) as p90,
        quantile(0.95)(used_time) as p95,
        quantile(0.99)(used_time) as p99,
        avg(used_time) as avg_latency
    FROM default.search_log
    WHERE created_at >= now() - INTERVAL 10 MINUTE
    GROUP BY time_minute
)
ORDER BY time_minute DESC;
```

## 性能优化版本（使用近似分位数）

对于海量数据，可以使用近似分位数函数提高查询性能：

```sql
SELECT
    toStartOfMinute(created_at) as time_minute,
    count(*) as request_count,
    min(used_time) as min_latency,
    max(used_time) as max_latency,
    quantileTDigest(0.50)(used_time) as p50_approx,
    quantileTDigest(0.90)(used_time) as p90_approx,
    quantileTDigest(0.95)(used_time) as p95_approx,
    quantileTDigest(0.99)(used_time) as p99_approx,
    avg(used_time) as avg_latency
FROM default.search_log
WHERE created_at >= now() - INTERVAL 1 HOUR
GROUP BY time_minute
ORDER BY time_minute DESC;
```

## 关键指标说明

- **P50**: 50%的请求延迟低于此值（中位数）
- **P90**: 90%的请求延迟低于此值
- **P95**: 95%的请求延迟低于此值
- **P99**: 99%的请求延迟低于此值（长尾延迟）
- **P999**: 99.9%的请求延迟低于此值（极端长尾）


请根据实际的 `status` 字段含义调整成功和失败的判断条件。
