```sql
-- 1. 查看所有集群配置
SELECT 
    cluster,
    shard_num,
    shard_weight,
    replica_num,
    host_name,
    host_address,
    port,
    is_local
FROM system.clusters;

SELECT * 
FROM system.clusters 
WHERE cluster = 'cycle_replica_cluster';
```

```sql
-- 1. 查看集群中所有节点的表
SELECT 
    hostName() as node,
    database,
    name as table_name,
    engine,
    total_rows,
    formatReadableSize(total_bytes) as size
FROM clusterAllReplicas('cycle_replica_cluster', system.tables)
WHERE engine NOT LIKE 'System%'
ORDER BY node, database, table_name
FORMAT PrettyCompact;

-- 2. 查看特定数据库的表（比如default）
SELECT 
    hostName() as node,
    name as table_name,
    engine,
    formatReadableSize(total_bytes) as size,
    partition_key,
    sorting_key,
    create_table_query
FROM clusterAllReplicas('cycle_replica_cluster', system.tables)
WHERE database = 'default'
  AND engine NOT LIKE 'System%'
ORDER BY node, table_name;

-- 3. 查看复制表状态
SELECT 
    hostName() as node,
    database,
    table,
    is_leader,
    total_replicas,
    active_replicas,
    replica_is_active
FROM clusterAllReplicas('cycle_replica_cluster', system.replicas)
WHERE database NOT LIKE 'system'
ORDER BY database, table, node;
```

## 创建表

```sql
-- 1. 创建优化的本地表
CREATE TABLE default.alarm_local ON CLUSTER 'cycle_replica_cluster'
(
    `service_name` String,
    `timestamp` DateTime64(3),
    `crawl_type` String,
    `type` String,
    `level` String,
    `message` String,
    `status` Int64,
    `created_at` DateTime64(3),
    
    -- 添加更多索引以提高查询性能
    INDEX idx_service_name service_name TYPE bloom_filter GRANULARITY 4,
    INDEX idx_type type TYPE bloom_filter GRANULARITY 4,
    INDEX idx_level level TYPE bloom_filter GRANULARITY 4,
    INDEX idx_status status TYPE minmax GRANULARITY 2,
    INDEX idx_timestamp timestamp TYPE minmax GRANULARITY 3,
    INDEX idx_created_at created_at TYPE minmax GRANULARITY 3
)
ENGINE = MergeTree
-- 根据timestamp排序，提高时间范围查询性能
ORDER BY (timestamp, service_name, type)
-- 按月份分区，方便数据管理
PARTITION BY toYYYYMM(timestamp)
TTL 
    timestamp + toIntervalDay(7) DELETE,                    -- 7天后删除
    timestamp + toIntervalDay(3) TO DISK 'default'          -- 3天后移到默认磁盘
SETTINGS 
    index_granularity = 8192,
    min_bytes_for_wide_part = 104857600,                    -- 100MB
    ttl_only_drop_parts = 1,                                -- 只删除整个分区，提高性能
    merge_with_ttl_timeout = 86400;                         -- TTL检查间隔24小时

-- 2. 创建分布式表，使用一致性哈希分发
CREATE TABLE default.alarm ON CLUSTER 'cycle_replica_cluster'
AS default.alarm_local
ENGINE = Distributed('cycle_replica_cluster', 'default', 'alarm_local', xxHash64(service_name, type));

-- 1. 创建本地表（在每个分片上）
CREATE TABLE default.general_logs_local ON CLUSTER 'cycle_replica_cluster'
(
    `timestamp` DateTime64(3, 'Asia/Shanghai') COMMENT '日志时间戳，精确到毫秒',
    `log_id` String COMMENT '日志唯一ID',
    `level` LowCardinality(String) COMMENT '日志级别: DEBUG/INFO/WARN/ERROR',
    `service_name` LowCardinality(String) COMMENT '服务名称',
    `module_name` LowCardinality(String) COMMENT '模块名称',
    `host` LowCardinality(String) COMMENT '主机名/IP',
    `trace_id` String COMMENT '链路追踪ID',
    `request_id` String COMMENT '请求ID',
    `user_id` Nullable(String) COMMENT '用户ID',
    `http_method` LowCardinality(String) COMMENT 'HTTP方法',
    `http_path` String COMMENT '请求路径',
    `http_status` Nullable(UInt16) COMMENT 'HTTP状态码',
    `client_ip` String COMMENT '客户端IP',
    `user_agent` String COMMENT 'User Agent',
    `logger_name` String COMMENT '日志记录器名称',
    `thread_name` String COMMENT '线程名称',
    `message` String COMMENT '日志消息',
    `stack_trace` String COMMENT '堆栈信息',
    `tags` String COMMENT '标签键值对',
    `metrics` String COMMENT '指标数值',
    `extra` String COMMENT '额外字段',
    `ingested_at` DateTime DEFAULT now() COMMENT '数据入库时间',
    `source` LowCardinality(String) DEFAULT 'app' COMMENT '数据来源',
    `version` LowCardinality(String) COMMENT '应用版本'
)
ENGINE = MergeTree
PARTITION BY toYYYYMMDD(timestamp)
ORDER BY (service_name, level, toDate(timestamp), timestamp)
TTL timestamp + toIntervalDay(7)
SETTINGS 
    index_granularity = 8192, 
    ttl_only_drop_parts = 1, 
    merge_with_ttl_timeout = 3600, 
    min_bytes_for_wide_part = 1073741824;

-- 2. 创建分布式表
CREATE TABLE default.general_logs ON CLUSTER 'cycle_replica_cluster'
AS default.general_logs_local
ENGINE = Distributed('cycle_replica_cluster', 'default', 'general_logs_local', xxHash64(log_id));
```

## 删除表

```sql
-- 本地表（复制表，适用于多副本）
CREATE TABLE proxy_host_local (
    ip IPv4,
    provider LowCardinality(String),
    country LowCardinality(String),
    region LowCardinality(String),
    idc LowCardinality(String),
    proxy_user String,
    created_at Date DEFAULT today()
) ENGINE = ReplicatedMergeTree(
    '/clickhouse/tables/{shard}/proxy_host_local',
    '{replica}'
)
PARTITION BY toYYYYMM(created_at)
PRIMARY KEY (ip)
ORDER BY (ip, country, region, provider)
SETTINGS index_granularity = 8192;

-- 分布式表
CREATE TABLE proxy_host AS proxy_host_local
ENGINE = Distributed('cycle_replica_cluster', 'default', 'proxy_host_local', xxHash64(ip));

-- 1. 删除分布式表（定义）
DROP TABLE IF EXISTS default.proxy_host ON CLUSTER cycle_replica_cluster;

-- 2. 删除本地表（数据+定义）
DROP TABLE IF EXISTS default.proxy_host_local ON CLUSTER cycle_replica_cluster;
```

## 创建用户

```sql
-- 1. 在集群中创建用户（在任意节点执行）
CREATE USER dev ON CLUSTER 'cycle_replica_cluster'
IDENTIFIED WITH sha256_password BY 'dev_password';

-- 2. 授予只读权限
GRANT SHOW DATABASES, SHOW TABLES, SELECT ON *.* TO dev ON CLUSTER 'cycle_replica_cluster';

-- 3. 限制访问的数据库（可选，更安全）
GRANT SELECT ON default.* TO dev ON CLUSTER 'cycle_replica_cluster';
GRANT SELECT ON system.* TO dev ON CLUSTER 'cycle_replica_cluster'; -- 允许查看系统表

-- 4. 设置只读配置
ALTER USER dev ON CLUSTER 'cycle_replica_cluster' SETTINGS readonly = 1;

-- 5. 限制网络访问（可选）
ALTER USER dev ON CLUSTER 'cycle_replica_cluster' 
SETTINGS 
    readonly = 1,
    max_execution_time = 30,
    max_memory_usage = 10000000000;
```
