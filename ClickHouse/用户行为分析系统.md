# 使用Go和ClickHouse开发用户行为分析系统

下面我将详细介绍如何使用Go语言和ClickHouse构建用户行为分析系统的完整步骤。

## 系统架构概述

```
用户客户端 → Go数据收集服务 → ClickHouse存储 → Go数据分析API → 前端展示
```

## 环境准备与部署

### 1. 部署ClickHouse

**使用Docker部署ClickHouse：**

```bash
# 创建数据目录
mkdir -p ~/clickhouse/data
mkdir -p ~/clickhouse/config

# 拉取ClickHouse镜像
docker pull clickhouse/clickhouse-server

# 运行ClickHouse容器
docker run -d \
  --name clickhouse-server \
  -p 8123:8123 \
  -p 9000:9000 \
  -p 9009:9009 \
  -v ~/clickhouse/data:/var/lib/clickhouse \
  -v ~/clickhouse/config:/etc/clickhouse-server \
  clickhouse/clickhouse-server
```

**验证安装：**
```bash
# 进入容器
docker exec -it clickhouse-server clickhouse-client

# 或从外部连接
clickhouse-client --host localhost --port 9000 --user default
```

### 2. 安装Go环境

```bash
# 下载并安装Go
wget https://golang.org/dl/go1.19.linux-amd64.tar.gz
sudo tar -C /usr/local -xzf go1.19.linux-amd64.tar.gz

# 设置环境变量
echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc
echo 'export GOPATH=$HOME/go' >> ~/.bashrc
source ~/.bashrc

# 验证安装
go version
```

## 数据库设计与建表

### 1. 创建数据库和表

在ClickHouse中执行以下SQL语句：

```sql
-- 创建数据库
CREATE DATABASE IF NOT EXISTS user_analytics;

-- 切换到数据库
USE user_analytics;

-- 创建用户事件表
CREATE TABLE IF NOT EXISTS user_events
(
    event_id UUID DEFAULT generateUUIDv4(),
    user_id UInt64,
    session_id String,
    event_type String,
    event_name String,
    page_url String,
    referrer String,
    device_type Enum8('desktop' = 1, 'mobile' = 2, 'tablet' = 3, 'other' = 4),
    browser String,
    os String,
    country_code FixedString(2),
    region String,
    city String,
    event_time DateTime64(3, 'UTC'),
    properties String,  -- JSON格式的额外属性
    created_at DateTime64(3, 'UTC') DEFAULT now()
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(event_time)
ORDER BY (event_time, user_id, event_type)
TTL event_time + INTERVAL 6 MONTH
SETTINGS index_granularity = 8192;

-- 创建分布式表（如果使用集群）
CREATE TABLE IF NOT EXISTS user_events_distributed AS user_events
ENGINE = Distributed(cluster_name, user_analytics, user_events, rand());

-- 创建物化视图用于常用聚合
CREATE MATERIALIZED VIEW IF NOT EXISTS user_events_daily_mv
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(event_time)
ORDER BY (event_time, event_type, country_code)
AS SELECT
    toDate(event_time) as event_date,
    event_type,
    country_code,
    count() as event_count,
    uniq(user_id) as unique_users
FROM user_events
GROUP BY event_date, event_type, country_code;
```

## Go应用开发

### 1. 项目初始化

```bash
# 创建项目目录
mkdir user-analytics-system
cd user-analytics-system

# 初始化Go模块
go mod init github.com/your-username/user-analytics-system

# 安装依赖
go get github.com/ClickHouse/clickhouse-go/v2
go get github.com/gin-gonic/gin
go get github.com/rs/zerolog/log
```

### 2. 项目结构

```
user-analytics-system/
├── cmd/
│   ├── collector/          # 数据收集服务
│   └── api/               # 数据分析API服务
├── internal/
│   ├── models/            # 数据模型
│   ├── repository/        # 数据访问层
│   └── service/           # 业务逻辑层
├── pkg/
│   └── clickhouse/        # ClickHouse客户端配置
└── configs/               # 配置文件
```

### 3. ClickHouse连接配置

创建 `pkg/clickhouse/client.go`:

```go
package clickhouse

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/ClickHouse/clickhouse-go/v2"
	"github.com/ClickHouse/clickhouse-go/v2/lib/driver"
)

type Config struct {
	Host     string
	Port     int
	Database string
	Username string
	Password string
}

func NewConnection(cfg Config) (driver.Conn, error) {
	conn, err := clickhouse.Open(&clickhouse.Options{
		Addr: []string{fmt.Sprintf("%s:%d", cfg.Host, cfg.Port)},
		Auth: clickhouse.Auth{
			Database: cfg.Database,
			Username: cfg.Username,
			Password: cfg.Password,
		},
		DialTimeout: 10 * time.Second,
		Settings: clickhouse.Settings{
			"max_execution_time": 60,
		},
		Compression: &clickhouse.Compression{
			Method: clickhouse.CompressionLZ4,
		},
	})
	
	if err != nil {
		return nil, err
	}
	
	ctx := context.Background()
	if err := conn.Ping(ctx); err != nil {
		return nil, err
	}
	
	log.Println("Connected to ClickHouse successfully")
	return conn, nil
}
```

### 4. 数据模型

创建 `internal/models/event.go`:

```go
package models

import (
	"encoding/json"
	"time"
)

type DeviceType int8

const (
	Desktop DeviceType = iota + 1
	Mobile
	Tablet
	Other
)

type UserEvent struct {
	EventID     string                 `json:"event_id" ch:"event_id"`
	UserID      uint64                 `json:"user_id" ch:"user_id"`
	SessionID   string                 `json:"session_id" ch:"session_id"`
	EventType   string                 `json:"event_type" ch:"event_type"`
	EventName   string                 `json:"event_name" ch:"event_name"`
	PageURL     string                 `json:"page_url" ch:"page_url"`
	Referrer    string                 `json:"referrer" ch:"referrer"`
	DeviceType  DeviceType             `json:"device_type" ch:"device_type"`
	Browser     string                 `json:"browser" ch:"browser"`
	OS          string                 `json:"os" ch:"os"`
	CountryCode string                 `json:"country_code" ch:"country_code"`
	Region      string                 `json:"region" ch:"region"`
	City        string                 `json:"city" ch:"city"`
	EventTime   time.Time              `json:"event_time" ch:"event_time"`
	Properties  map[string]interface{} `json:"properties" ch:"properties"`
	CreatedAt   time.Time              `json:"created_at" ch:"created_at"`
}

func (e *UserEvent) MarshalProperties() string {
	if e.Properties == nil {
		return "{}"
	}
	bytes, _ := json.Marshal(e.Properties)
	return string(bytes)
}
```

### 5. 数据访问层

创建 `internal/repository/event_repository.go`:

```go
package repository

import (
	"context"
	"fmt"
	"time"

	"github.com/your-username/user-analytics-system/internal/models"
	"github.com/ClickHouse/clickhouse-go/v2/lib/driver"
)

type EventRepository struct {
	conn driver.Conn
}

func NewEventRepository(conn driver.Conn) *EventRepository {
	return &EventRepository{conn: conn}
}

func (r *EventRepository) Insert(event *models.UserEvent) error {
	query := `
		INSERT INTO user_events (
			user_id, session_id, event_type, event_name, 
			page_url, referrer, device_type, browser, os, 
			country_code, region, city, event_time, properties
		) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
	`
	
	return r.conn.AsyncInsert(context.Background(), query, false,
		event.UserID,
		event.SessionID,
		event.EventType,
		event.EventName,
		event.PageURL,
		event.Referrer,
		event.DeviceType,
		event.Browser,
		event.OS,
		event.CountryCode,
		event.Region,
		event.City,
		event.EventTime,
		event.MarshalProperties(),
	)
}

func (r *EventRepository) GetEventsByTimeRange(start, end time.Time, limit uint64) ([]models.UserEvent, error) {
	query := `
		SELECT 
			event_id, user_id, session_id, event_type, event_name,
			page_url, referrer, device_type, browser, os,
			country_code, region, city, event_time, properties, created_at
		FROM user_events 
		WHERE event_time >= ? AND event_time <= ?
		ORDER BY event_time DESC
		LIMIT ?
	`
	
	rows, err := r.conn.Query(context.Background(), query, start, end, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	
	var events []models.UserEvent
	for rows.Next() {
		var event models.UserEvent
		var propertiesStr string
		
		if err := rows.Scan(
			&event.EventID,
			&event.UserID,
			&event.SessionID,
			&event.EventType,
			&event.EventName,
			&event.PageURL,
			&event.Referrer,
			&event.DeviceType,
			&event.Browser,
			&event.OS,
			&event.CountryCode,
			&event.Region,
			&event.City,
			&event.EventTime,
			&propertiesStr,
			&event.CreatedAt,
		); err != nil {
			return nil, err
		}
		
		// 解析JSON属性
		if err := json.Unmarshal([]byte(propertiesStr), &event.Properties); err != nil {
			return nil, fmt.Errorf("failed to unmarshal properties: %v", err)
		}
		
		events = append(events, event)
	}
	
	return events, nil
}

// 添加更多分析方法，如获取用户行为 funnel、留存率等
```

### 6. 数据收集服务

创建 `cmd/collector/main.go`:

```go
package main

import (
	"encoding/json"
	"net/http"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/rs/zerolog/log"
	"github.com/your-username/user-analytics-system/internal/models"
	"github.com/your-username/user-analytics-system/internal/repository"
	"github.com/your-username/user-analytics-system/pkg/clickhouse"
)

func main() {
	// 初始化ClickHouse连接
	cfg := clickhouse.Config{
		Host:     "localhost",
		Port:     9000,
		Database: "user_analytics",
		Username: "default",
		Password: "",
	}
	
	conn, err := clickhouse.NewConnection(cfg)
	if err != nil {
		log.Fatal().Err(err).Msg("Failed to connect to ClickHouse")
	}
	defer conn.Close()
	
	// 初始化仓库
	eventRepo := repository.NewEventRepository(conn)
	
	// 初始化Gin路由
	router := gin.Default()
	
	// 健康检查端点
	router.GET("/health", func(c *gin.Context) {
		c.JSON(http.StatusOK, gin.H{"status": "ok"})
	})
	
	// 事件收集端点
	router.POST("/track", func(c *gin.Context) {
		var event models.UserEvent
		if err := c.BindJSON(&event); err != nil {
			c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
			return
		}
		
		// 设置事件时间（如果未提供）
		if event.EventTime.IsZero() {
			event.EventTime = time.Now().UTC()
		}
		
		// 存储事件
		if err := eventRepo.Insert(&event); err != nil {
			log.Error().Err(err).Msg("Failed to insert event")
			c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to track event"})
			return
		}
		
		c.JSON(http.StatusOK, gin.H{"status": "success"})
	})
	
	// 批量事件收集端点
	router.POST("/batch", func(c *gin.Context) {
		var events []models.UserEvent
		if err := c.BindJSON(&events); err != nil {
			c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
			return
		}
		
		for _, event := range events {
			if event.EventTime.IsZero() {
				event.EventTime = time.Now().UTC()
			}
			
			if err := eventRepo.Insert(&event); err != nil {
				log.Error().Err(err).Msg("Failed to insert event in batch")
				// 可以继续处理其他事件或中断，根据需求决定
			}
		}
		
		c.JSON(http.StatusOK, gin.H{"status": "success", "processed": len(events)})
	})
	
	// 启动服务器
	log.Info().Msg("Starting collector server on :8080")
	if err := router.Run(":8080"); err != nil {
		log.Fatal().Err(err).Msg("Failed to start server")
	}
}
```

### 7. 数据分析API服务

创建 `cmd/api/main.go`:

```go
package main

import (
	"net/http"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/rs/zerolog/log"
	"github.com/your-username/user-analytics-system/internal/repository"
	"github.com/your-username/user-analytics-system/pkg/clickhouse"
)

func main() {
	// 初始化ClickHouse连接
	cfg := clickhouse.Config{
		Host:     "localhost",
		Port:     9000,
		Database: "user_analytics",
		Username: "default",
		Password: "",
	}
	
	conn, err := clickhouse.NewConnection(cfg)
	if err != nil {
		log.Fatal().Err(err).Msg("Failed to connect to ClickHouse")
	}
	defer conn.Close()
	
	// 初始化仓库
	eventRepo := repository.NewEventRepository(conn)
	
	// 初始化Gin路由
	router := gin.Default()
	
	// 获取事件数据
	router.GET("/events", func(c *gin.Context) {
		startTime := c.Query("start_time")
		endTime := c.Query("end_time")
		limit := c.DefaultQuery("limit", "100")
		
		var start, end time.Time
		var err error
		
		if startTime != "" {
			start, err = time.Parse(time.RFC3339, startTime)
			if err != nil {
				c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid start_time format"})
				return
			}
		} else {
			start = time.Now().AddDate(0, 0, -7) // 默认过去7天
		}
		
		if endTime != "" {
			end, err = time.Parse(time.RFC3339, endTime)
			if err != nil {
				c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid end_time format"})
				return
			}
		} else {
			end = time.Now()
		}
		
		events, err := eventRepo.GetEventsByTimeRange(start, end, 100)
		if err != nil {
			log.Error().Err(err).Msg("Failed to fetch events")
			c.JSON(http.StatusInternalServerError, gin.H{"error": "Failed to fetch events"})
			return
		}
		
		c.JSON(http.StatusOK, events)
	})
	
	// 获取分析指标
	router.GET("/metrics/:type", func(c *gin.Context) {
		metricType := c.Param("type")
		startTime := c.Query("start_time")
		endTime := c.Query("end_time")
		
		// 实现各种分析指标查询
		switch metricType {
		case "daily-active-users":
			// 实现DAU查询
		case "retention":
			// 实现留存率查询
		case "funnel":
			// 实现漏斗分析
		default:
			c.JSON(http.StatusBadRequest, gin.H{"error": "Unknown metric type"})
		}
	})
	
	// 启动服务器
	log.Info().Msg("Starting API server on :8081")
	if err := router.Run(":8081"); err != nil {
		log.Fatal().Err(err).Msg("Failed to start server")
	}
}
```

## 部署和运行

### 1. 构建和运行服务

```bash
# 构建数据收集服务
go build -o collector ./cmd/collector

# 构建API服务
go build -o api ./cmd/api

# 运行服务
./collector &
./api &
```

### 2. 使用Docker Compose部署（可选）

创建 `docker-compose.yml`:

```yaml
version: '3.8'

services:
  clickhouse:
    image: clickhouse/clickhouse-server
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_config:/etc/clickhouse-server
    environment:
      - CLICKHOUSE_DB=user_analytics
      - CLICKHOUSE_USER=admin
      - CLICKHOUSE_PASSWORD=secret

  collector:
    build:
      context: .
      dockerfile: Dockerfile.collector
    ports:
      - "8080:8080"
    depends_on:
      - clickhouse
    environment:
      - CH_HOST=clickhouse
      - CH_PORT=9000
      - CH_DB=user_analytics
      - CH_USER=admin
      - CH_PASSWORD=secret

  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8081:8081"
    depends_on:
      - clickhouse
    environment:
      - CH_HOST=clickhouse
      - CH_PORT=9000
      - CH_DB=user_analytics
      - CH_USER=admin
      - CH_PASSWORD=secret

volumes:
  clickhouse_data:
  clickhouse_config:
```

## 测试系统

### 1. 发送测试事件

```bash
curl -X POST http://localhost:8080/track \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": 12345,
    "session_id": "session_abc",
    "event_type": "page_view",
    "event_name": "homepage",
    "page_url": "https://example.com",
    "referrer": "https://google.com",
    "device_type": 2,
    "browser": "Chrome",
    "os": "Android",
    "country_code": "US",
    "region": "California",
    "city": "San Francisco",
    "properties": {"load_time": 1.2, "scroll_depth": 75}
  }'
```

### 2. 查询事件数据

```bash
curl "http://localhost:8081/events?start_time=2023-01-01T00:00:00Z&end_time=2023-12-31T23:59:59Z&limit=10"
```

## 性能优化建议

1. **使用批量插入**：尽量使用批量接口减少插入操作次数
2. **调整ClickHouse配置**：根据数据量调整内存和线程设置
3. **使用数据分区**：按时间分区提高查询性能
4. **添加索引**：为常用查询字段添加索引
5. **使用物化视图**：预计算常用聚合指标

## 监控和维护

1. 监控ClickHouse的系统指标（CPU、内存、磁盘使用率）
2. 定期清理过期数据
3. 监控查询性能，优化慢查询
4. 设置报警规则用于系统异常检测

这个系统提供了一个完整的用户行为分析基础架构，你可以根据具体需求进一步扩展功能，如实时分析看板、用户分群、路径分析等高级功能。

---

### 一、系统架构设计
1. **分层架构**  
    - **数据采集层**：用户行为埋点数据通过Kafka实时接入，结合Flink清洗关联用户属性。  
    - **存储层**：  
      - 行为明细表：`ReplicatedReplacingMergeTree`引擎存储原始行为数据，按用户ID分片（`user_id % shard_num`）确保单用户数据位于同一分片。  
      - 聚合表：`AggregatingMergeTree`引擎预计算留存/漏斗指标，减少实时计算量。  
    - **计算层**：利用分布式表（Distributed Table）并行查询，通过本地表（Local Table）避免写入瓶颈。

2. **数据路由优化**  
    - 避免直接写分布式表：通过MapReduce任务按`user_id`哈希路由到本地表，减少ZooKeeper压力。  
    - 分片数据解耦：同一用户行为仅存于一个分片，实现无跨节点GROUP BY。

---

### 二、数据建模方案
#### 1. 行为明细表
```sql
CREATE TABLE user_events_local ON CLUSTER cluster_name (
    `user_id` UInt64,
    `event_time` DateTime,
    `event_name` String,
    `city` String,
    `device` String,
    `session_id` String
) ENGINE = ReplicatedReplacingMergeTree()
PARTITION BY toYYYYMM(event_time)
ORDER BY (user_id, event_time)
SETTINGS index_granularity = 8192;
```
- **字段说明**：`event_name`（事件名如“login”、“purchase”）、`session_id`（会话标识）。

#### 2. 用户画像宽表
```sql
CREATE TABLE user_profiles_local ON CLUSTER cluster_name (
    `user_id` UInt64,
    `age` UInt8,
    `gender` String,
    `vip_level` UInt8,
    `last_active_date` Date
) ENGINE = ReplicatedReplacingMergeTree()
ORDER BY user_id;
```
- **优化**：行为分析时通过`JOIN`画像宽表，避免实时关联。

---

### 三、核心分析SQL实现
#### 1. **漏斗分析（7步转化）**
```sql
SELECT
    level_index AS step,
    count(1) AS current_users,
    neighbor(current_users, -1) AS previous_users,
    round(current_users / previous_users * 100, 2) AS conversion_rate
FROM (
    SELECT
        level_index,
        user_id
    FROM (
        SELECT
            user_id,
            arrayJoin(arrayEnumerate(arrayWithConstant(level, 1))) AS level_index
        FROM (
            SELECT
                user_id,
                windowFunnel(604800)(event_time,  -- 7天窗口期
                    event_name = 'view_home',
                    event_name = 'click_banner',
                    event_name = 'add_to_cart',
                    event_name = 'confirm_order',
                    event_name = 'payment'
                ) AS level
            FROM user_events_distributed
            WHERE event_time >= now() - INTERVAL 30 DAY
            GROUP BY user_id
        )
        WHERE level >= 1
    )
    GROUP BY level_index
)
ORDER BY step ASC;
```
- **说明**：`windowFunnel`返回用户最大转化步数，`arrayEnumerate`展开为步骤明细。

#### 2. **多周期留存分析（1/3/7/30日）**
```sql
SELECT
    toDate(first_day) AS start_date,
    retention[1] AS retained_1d,
    retention[2] AS retained_3d,
    retention[3] AS retained_7d,
    retention[4] AS retained_30d,
    retained_1d / start_users AS rate_1d,
    retained_3d / start_users AS rate_3d
FROM (
    SELECT
        first_day,
        count() AS start_users,
        retention(
            toDate(event_time) = first_day,  -- 起始事件（如注册）
            toDate(event_time) = first_day + INTERVAL 1 DAY,  -- 1日留存
            toDate(event_time) = first_day + INTERVAL 3 DAY,  -- 3日留存
            toDate(event_time) = first_day + INTERVAL 7 DAY,  -- 7日留存
            toDate(event_time) = first_day + INTERVAL 30 DAY   -- 30日留存
        ) AS retention
    FROM (
        SELECT
            user_id,
            min(toDate(event_time)) AS first_day
        FROM user_events_distributed
        WHERE event_name = 'register'
        GROUP BY user_id
    ) AS start_users
    LEFT JOIN user_events_distributed USING (user_id)
    GROUP BY first_day
);
```
- **说明**：`retention`函数按位标记用户是否满足各时间点条件。

#### 3. **用户画像圈选**
```sql
-- 筛选高价值流失用户（30日内活跃但近7日未付费）
SELECT
    city,
    device,
    countDistinct(user_id) AS users
FROM user_events_distributed
WHERE user_id IN (
    SELECT user_id
    FROM user_profiles_distributed
    WHERE vip_level >= 3
        AND last_active_date >= today() - INTERVAL 30 DAY
        AND user_id NOT IN (
            SELECT user_id
            FROM user_events_distributed
            WHERE event_name = 'payment'
                AND event_time >= now() - INTERVAL 7 DAY
        )
)
GROUP BY city, device;
```

---

### 四、关键优化策略
1. **预计算加速**  
   - 使用`AggregatingMergeTree`预存每日留存结果，查询时直接汇总。  
   - 漏斗分析结果物化到`MATERIALIZED VIEW`。

2. **Bitmap高效人群计算**  
   ```sql
   -- 使用RoaringBitmap计算7日活跃用户
   SELECT groupBitmap(user_id) AS active_users 
   FROM user_events_distributed 
   WHERE event_time >= now() - INTERVAL 7 DAY;
   ```
   - **优势**：压缩存储，支持交并差集运算（`bitmapAnd`/`bitmapOr`）。

3. **分区裁剪与索引**  
   - 按时间分区（`PARTITION BY toYYYYMM(event_time)`），结合`ORDER BY (user_id, event_time)`加速用户行为序列查询。

---

## 常用分析 SQL

# ClickHouse 用户行为分析SQL示例

下面提供一些常用的用户行为分析SQL查询示例，包括漏斗分析、留存分析等。

## 1. 漏斗分析SQL

### 基本漏斗分析（按事件序列）
```sql
-- 分析从浏览->加入购物车->购买的转化漏斗
WITH 
    'page_view' AS step1,
    'add_to_cart' AS step2,
    'purchase' AS step3
SELECT
    countIf(has_step1) AS step1_users,
    countIf(has_step1 AND has_step2) AS step2_users,
    countIf(has_step1 AND has_step2 AND has_step3) AS step3_users,
    round(step2_users / step1_users * 100, 2) AS step1_to_step2_conversion,
    round(step3_users / step2_users * 100, 2) AS step2_to_step3_conversion,
    round(step3_users / step1_users * 100, 2) AS overall_conversion
FROM (
    SELECT
        user_id,
        maxIf(1, event_name = step1) AS has_step1,
        maxIf(1, event_name = step2) AS has_step2,
        maxIf(1, event_name = step3) AS has_step3
    FROM user_events
    WHERE event_time >= today() - 7
    GROUP BY user_id
)
```

### 时间窗口漏斗分析（7天内完成所有步骤）
```sql
-- 分析7天内完成浏览->加入购物车->购买的用户漏斗
WITH 
    'page_view' AS step1,
    'add_to_cart' AS step2,
    'purchase' AS step3
SELECT
    countIf(has_step1) AS step1_users,
    countIf(has_step1 AND has_step2 AND step2_time - step1_time <= interval 7 day) AS step2_users,
    countIf(has_step1 AND has_step2 AND has_step3 AND step2_time - step1_time <= interval 7 day AND step3_time - step2_time <= interval 7 day) AS step3_users,
    round(step2_users / step1_users * 100, 2) AS step1_to_step2_conversion,
    round(step3_users / step2_users * 100, 2) AS step2_to_step3_conversion,
    round(step3_users / step1_users * 100, 2) AS overall_conversion
FROM (
    SELECT
        user_id,
        maxIf(1, event_name = step1) AS has_step1,
        maxIf(1, event_name = step2) AS has_step2,
        maxIf(1, event_name = step3) AS has_step3,
        minIf(event_time, event_name = step1) AS step1_time,
        minIf(event_time, event_name = step2) AS step2_time,
        minIf(event_time, event_name = step3) AS step3_time
    FROM user_events
    WHERE event_time >= today() - 30
    GROUP BY user_id
)
```

### 多步骤漏斗分析（可扩展）
```sql
-- 创建可扩展的多步骤漏斗分析函数
SELECT
    windowFunnel(604800)( -- 7天时间窗口(604800秒)
        event_time,
        event_name = 'page_view',
        event_name = 'add_to_cart',
        event_name = 'initiate_checkout',
        event_name = 'purchase'
    ) AS funnel_steps,
    count() AS user_count
FROM user_events
WHERE event_time >= now() - INTERVAL 30 DAY
GROUP BY funnel_steps
ORDER BY funnel_steps
```

## 2. 留存分析SQL

### 每日新增用户留存分析
```sql
-- 计算每日新增用户的第1、7、30日留存率
WITH 
    first_events AS (
        SELECT
            user_id,
            min(toDate(event_time)) AS first_date
        FROM user_events
        WHERE event_time >= today() - 60
        GROUP BY user_id
    ),
    daily_activity AS (
        SELECT
            user_id,
            toDate(event_time) AS active_date
        FROM user_events
        WHERE event_time >= today() - 60
        GROUP BY user_id, toDate(event_time)
    )
SELECT
    first_date AS cohort_date,
    count(distinct user_id) AS cohort_size,
    count(distinct if(active_date = first_date + 1, user_id, NULL)) AS day1_retained,
    count(distinct if(active_date = first_date + 7, user_id, NULL)) AS day7_retained,
    count(distinct if(active_date = first_date + 30, user_id, NULL)) AS day30_retained,
    round(day1_retained / cohort_size * 100, 2) AS day1_retention_rate,
    round(day7_retained / cohort_size * 100, 2) AS day7_retention_rate,
    round(day30_retained / cohort_size * 100, 2) AS day30_retention_rate
FROM first_events
JOIN daily_activity USING (user_id)
WHERE first_date >= today() - 30
GROUP BY first_date
ORDER BY first_date
```

### 留存矩阵（Cohort分析）
```sql
-- 创建留存矩阵，显示不同时间段的留存情况
WITH 
    first_events AS (
        SELECT
            user_id,
            toMonday(min(event_time)) AS first_week
        FROM user_events
        WHERE event_time >= today() - 90
        GROUP BY user_id
    ),
    weekly_activity AS (
        SELECT
            user_id,
            toMonday(event_time) AS active_week
        FROM user_events
        WHERE event_time >= today() - 90
        GROUP BY user_id, toMonday(event_time)
    )
SELECT
    first_week,
    count(distinct user_id) AS cohort_size,
    count(distinct if(active_week = first_week, user_id, NULL)) AS week0,
    count(distinct if(active_week = first_week + 7, user_id, NULL)) AS week1,
    count(distinct if(active_week = first_week + 14, user_id, NULL)) AS week2,
    count(distinct if(active_week = first_week + 21, user_id, NULL)) AS week3,
    count(distinct if(active_week = first_week + 28, user_id, NULL)) AS week4,
    round(week1 / cohort_size * 100, 1) AS week1_retention,
    round(week2 / cohort_size * 100, 1) AS week2_retention,
    round(week3 / cohort_size * 100, 1) AS week3_retention,
    round(week4 / cohort_size * 100, 1) AS week4_retention
FROM first_events
JOIN weekly_activity USING (user_id)
WHERE first_week >= today() - 60
GROUP BY first_week
ORDER BY first_week
```

## 3. 用户行为路径分析

### 用户最常见的路径分析
```sql
-- 分析用户最常见的行为路径（前10条路径）
SELECT
    path,
    count() AS path_count
FROM (
    SELECT
        user_id,
        session_id,
        groupArray(event_name) AS path
    FROM (
        SELECT
            user_id,
            session_id,
            event_name,
            event_time
        FROM user_events
        WHERE event_time >= today() - 7
        ORDER BY user_id, session_id, event_time
    )
    GROUP BY user_id, session_id
)
GROUP BY path
ORDER BY path_count DESC
LIMIT 10
```

### 热门页面流转分析
```sql
-- 分析页面之间的流转情况
SELECT
    previous_page,
    current_page,
    count() AS transition_count
FROM (
    SELECT
        user_id,
        session_id,
        page_url AS current_page,
        neighbor(page_url, -1) AS previous_page
    FROM (
        SELECT
            user_id,
            session_id,
            page_url,
            event_time
        FROM user_events
        WHERE event_name = 'page_view' AND event_time >= today() - 7
        ORDER BY user_id, session_id, event_time
    )
)
WHERE previous_page != ''
GROUP BY previous_page, current_page
ORDER BY transition_count DESC
LIMIT 20
```

## 4. 用户活跃度分析

### 每日活跃用户(DAU)和每月活跃用户(MAU)
```sql
-- 计算DAU、MAU以及DAU/MAU比率
SELECT
    toDate(event_time) AS date,
    count(distinct user_id) AS dau,
    count(distinct if(event_time >= today() - 30, user_id, NULL)) AS mau,
    round(dau / mau * 100, 2) AS engagement_ratio
FROM user_events
WHERE event_time >= today() - 60
GROUP BY date
ORDER BY date
```

### 用户活跃度分布
```sql
-- 分析用户活跃度分布（按事件数量）
SELECT
    activity_level,
    count() AS user_count
FROM (
    SELECT
        user_id,
        count() AS event_count,
        CASE
            WHEN event_count >= 100 THEN '超级活跃'
            WHEN event_count >= 50 THEN '高度活跃'
            WHEN event_count >= 20 THEN '中度活跃'
            WHEN event_count >= 5 THEN '轻度活跃'
            ELSE '不活跃'
        END AS activity_level
    FROM user_events
    WHERE event_time >= today() - 30
    GROUP BY user_id
)
GROUP BY activity_level
ORDER BY user_count DESC
```

## 5. 用户分群分析

### 新老用户行为对比
```sql
-- 比较新用户和老用户的行为差异
WITH user_cohorts AS (
    SELECT
        user_id,
        if(min(toDate(event_time)) >= today() - 7, 'new', 'existing') AS cohort
    FROM user_events
    WHERE event_time >= today() - 30
    GROUP BY user_id
)
SELECT
    cohort,
    count(distinct user_id) AS users,
    count(*) AS total_events,
    round(count(*) / count(distinct user_id), 1) AS events_per_user,
    count(distinct session_id) AS total_sessions,
    round(count(distinct session_id) / count(distinct user_id), 1) AS sessions_per_user,
    round(avgIf(1, event_name = 'purchase'), 3) AS conversion_rate
FROM user_events
JOIN user_cohorts USING (user_id)
WHERE event_time >= today() - 7
GROUP BY cohort
```

### 按设备类型分析用户行为
```sql
-- 分析不同设备类型用户的行为差异
SELECT
    device_type,
    count(distinct user_id) AS users,
    count(*) AS total_events,
    round(count(*) / count(distinct user_id), 1) AS events_per_user,
    round(avgIf(1, event_name = 'purchase'), 3) AS conversion_rate,
    round(avg(parseJSON(properties).load_time), 2) AS avg_load_time
FROM user_events
WHERE event_time >= today() - 7
GROUP BY device_type
ORDER BY users DESC
```

## 6. 事件分析

### 事件趋势分析
```sql
-- 分析关键事件的日趋势
SELECT
    toDate(event_time) AS date,
    event_name,
    count(*) AS event_count,
    count(distinct user_id) AS unique_users
FROM user_events
WHERE event_time >= today() - 30
    AND event_name IN ('page_view', 'add_to_cart', 'purchase')
GROUP BY date, event_name
ORDER BY date, event_name
```

### 事件属性分析
```sql
-- 分析特定事件的属性分布
SELECT
    parseJSON(properties).button_color AS button_color,
    count(*) AS click_count,
    count(distinct user_id) AS unique_users
FROM user_events
WHERE event_name = 'button_click'
    AND event_time >= today() - 7
    AND button_color != ''
GROUP BY button_color
ORDER BY click_count DESC
```

## 7. 会话分析

### 会话时长分析
```sql
-- 分析用户会话时长分布
SELECT
    session_duration_sec,
    count() AS session_count
FROM (
    SELECT
        user_id,
        session_id,
        max(event_time) - min(event_time) AS session_duration_sec
    FROM user_events
    WHERE event_time >= today() - 7
    GROUP BY user_id, session_id
    HAVING session_duration_sec <= 3600 -- 过滤掉超过1小时的会话（可能是异常）
)
GROUP BY session_duration_sec
ORDER BY session_duration_sec
```

### 会话深度分析
```sql
-- 分析用户会话深度（每会话事件数量）
SELECT
    events_per_session,
    count() AS session_count
FROM (
    SELECT
        user_id,
        session_id,
        count() AS events_per_session
    FROM user_events
    WHERE event_time >= today() - 7
    GROUP BY user_id, session_id
)
GROUP BY events_per_session
ORDER BY events_per_session
```

## 性能优化提示

1. 对于常用分析，考虑创建物化视图预计算结果：
```sql
-- 创建每日事件汇总的物化视图
CREATE MATERIALIZED VIEW user_events_daily_mv
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(event_date)
ORDER BY (event_date, event_type, country_code)
AS SELECT
    toDate(event_time) AS event_date,
    event_type,
    country_code,
    count() AS event_count,
    uniq(user_id) AS unique_users
FROM user_events
GROUP BY event_date, event_type, country_code;
```

2. 为常用查询字段添加索引：
```sql
-- 添加索引（如果尚未添加）
ALTER TABLE user_events ADD INDEX event_time_idx (event_time) TYPE minmax GRANULARITY 32;
ALTER TABLE user_events ADD INDEX event_name_idx (event_name) TYPE set(0) GRANULARITY 32;
ALTER TABLE user_events ADD INDEX user_id_idx (user_id) TYPE set(0) GRANULARITY 32;
```

这些SQL查询示例涵盖了用户行为分析中的常见场景，您可以根据实际业务需求进行调整和扩展。在实际使用时，请注意根据数据量和性能需求适当调整时间范围和查询条件。
