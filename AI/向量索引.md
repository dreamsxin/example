ANNS 算法：ScaNN、IVF_FLAT、HNSW

## 一、向量检索的场景
传统的搜索，使用关键做精确的查找，利用倒排索引在索引库中搜索。日常在用的百度，Google都属于关键词搜索。

在 AI 时代，我们需要查找一张相似的图片，一个问题的答案，或者根据一段音乐查找对应的歌曲，这些情况下没有准确的关键词用来做检索。 这些图片，问题（文本），语音，不再是简单的一个一维量化的数字，而是包含了大量的属性特征。 因而不合适使用传统的关键字搜索引擎来查找。

对于文本，图片，语音，视频，DNA信息等等，都可以用向量来表示，数据被特征化处理后，用来表示这条数据的向量称之为 Embedding。

比如 I love China, and I love the world. 这一句话， 假设在特定的语料集中, I, love, China, and, the, world 这几个 词语的词频分别是 2000, 300, 80, 1550, 2650, 850，

那么这个句子可以表示成 [2000, 300, 80, 1550, 2000, 300, 2650, 850] 的向量。 这是一个简单的用向量来表示文本的例子， 当然实际的情况会更复杂一些。

## 二、向量检索的4个要素
向量检索引擎里面包含了下面的这四个要素。

- 特征提取算法
- 距离度量算法
- 检索算法
- 数据存储

### 特征提取算法，对于不同类别的数据，有不同的提取方法，分别提取出来 Word Embedding, image feature, audio feature 等等。

词语的 Embedding 特征提取，可以使用 Word2Vec，也可以使用 Glove, Elmo, BERT, fastText 等方法。

图片的特征提取，可以使用 CNN 卷积，人脸特征可以使用 DLIB。

语音的特征提取，可以使用 FFT 做傅里叶变换。

### 距离的度量算法，常用的有 L2 欧几里得距离（空间距离）, IP 内积算法（相似度计算），Cosine 相似度等等。 距离越近则表示两个数据越相近。

不同距离计算值的含义： 利用L2 欧几里得距离，计算向量的相似度，欧式距离越小相似度越大（两个点的绝对距离）。 IP内积/夹角余弦越小表示两向量的夹角越大，则两个向量差异越大。当两个向量的方向重合时夹角余弦取最大值1，当两个向量的方向完全相反夹角余弦取最小值-1。 如果向量没有归一化，IP 内积的值大小是可以大于1的，且跟两个向量的长度有关。

### 检索的算法，可以使用暴力检索，可以使用 KNN （K Nearest Neighbor） 的聚类算法。也可以使用各种 KNN 的演进版本做更有效的检索。 KNN 通过聚类，把数据聚集到 K 个中心点，然后查找目标数据的时候，通过首先跟这 K 个中心点做距离比较，快速找到目标数据最近的中心点（可以是1个或者多个）， 然后再找附近的相似点，从而减少要查找的数据量，高效地检索到相近的数据。

向量索引学术上对应的专有名词叫Approximate Nearest Neighbor Search (ANNS)，即近似最近邻搜索。为什么是近似，而不是我们想要的精确？这就是精度与时间、算力资源的折中，采用了牺牲精度换取时间和空间的方式，从海量的样本中实时获取跟查询最相似的样本。

所谓近似检索，就是通过聚类、降维或者编码等方式，将原来需要在整个高维向量空间内的搜索，转换为在小范围空间或者相对低维的向量空间内搜索的算法。这类算法的特点是，检索的时间复杂度小于 O(Nd)，但是真正用来搜索之前，需要用一个向量分布类似的一个训练集来训练，获得一个产生合理数据划分或者编码的模型。然后再利用这个模型，使用额外的存储空间，建立对整个高维向量的索引。

虽然是近似的搜索，但在实际的生产环境应用中，可以通过调整参数，比较容易得达到 99%以上的召回率，甚至更接近 100% 的召回率的效果。

## 根据实现方法，ANNS向量索引可以分为4类：

- 基于树的索引
- 基于图的索引
- 基于哈希的索引
- 基于量化的索引

## 根据数据类型，支持2种类型的索引：

- floating-point embeddings
  SCANN、IVF_FLAT、IVF_PQ、IVF_SQ8、FLAT、HNSW、ANNOY、AUTOINDEX、DISKANN

- binary embeddings
  BIN_FLAT、BIN_IVF_FLAT

## milvus 
支持的向量索引类型大部分使用近似最近邻搜索算法(ANNS,approximate nearest neighbors search) 。ANNS 的核心思想不再局限于返回最准确的结果，而是仅搜索目标的邻居。 ANNS 通过在可接受的范围内牺牲准确性来提高检索效率。

## Faiss
Faiss的全称是Facebook AI Similarity Search，是FaceBook的AI团队针对大规模相似度检索问题开发的一个工具，使用C++编写，有python接口，对10亿量级的索引可以做到毫秒级检索的性能。

Faiss提供了多种索引结构，包括：

- IVF（Index Vector Forest）：一种基于决策树的索引，通过将数据分成多个子空间并存储索引信息，实现了高效的相似性搜索。
- Flat Index：最基础的索引结构，适用于数据量较小的情况，可实现全局搜索但效率较低。
- Tree Index：基于树结构的索引，通过对数据分层抽样和聚类，提高了搜索效率。
- BIT-Faiss：基于稀疏编码的索引，适用于大规模数据，通过编码和位操作降低了计算复杂度。
