# Go语言实现字符串相似度计算示例

## 环境准备

### 安装常用库
```bash
# 字符串相似度库
go get github.com/texttheater/golang-levenshtein/levenshtein
go get github.com/adrg/strutil
go get github.com/adrg/strutil/metrics
go get github.com/antzucaro/matchr

# 集合运算和通用工具
go get github.com/schollz/closestmatch
go get github.com/umahmood/haversine

# 生物信息学相关（如需）
go get github.com/biogo/biogo
```

## 1. 人名/地址匹配 - Jaro-Winkler

```go
package main

import (
    "fmt"
    "sort"
    "github.com/adrg/strutil"
    "github.com/adrg/strutil/metrics"
)

type MatchResult struct {
    Name       string
    Similarity float64
    Algorithm  string
}

// Jaro-Winkler 匹配
func MatchNamesJaroWinkler(names []string, target string, threshold float64) []MatchResult {
    var matches []MatchResult
    jw := metrics.NewJaroWinkler()
    
    for _, name := range names {
        similarity := jw.Compare(target, name)
        
        if similarity >= threshold {
            matches = append(matches, MatchResult{
                Name:       name,
                Similarity: similarity,
                Algorithm:  "Jaro-Winkler",
            })
        }
    }
    
    // 按相似度降序排序
    sort.Slice(matches, func(i, j int) bool {
        return matches[i].Similarity > matches[j].Similarity
    })
    
    return matches
}

// 综合字符串相似度（多算法）
func StringSimilarity(s1, s2 string) map[string]float64 {
    result := make(map[string]float64)
    
    // Jaro-Winkler
    jw := metrics.NewJaroWinkler()
    result["jaro_winkler"] = jw.Compare(s1, s2)
    
    // Jaro
    jaro := metrics.NewJaro()
    result["jaro"] = jaro.Compare(s1, s2)
    
    // Levenshtein（归一化）
    lev := metrics.NewLevenshtein()
    result["levenshtein"] = 1 - lev.Compare(s1, s2)
    
    // Smith-Waterman（近似）
    sw := metrics.NewSmithWatermanGotoh()
    result["smith_waterman"] = sw.Compare(s1, s2)
    
    // 使用strutil综合相似度
    result["overall"] = strutil.Similarity(s1, s2, jw)
    
    return result
}

func main() {
    // 示例：人名匹配
    names := []string{
        "John Smith",
        "Jon Smith",
        "John Smyth",
        "Jane Doe",
        "John S. Smith",
        "J. Smith",
    }
    
    target := "John Smith"
    threshold := 0.8
    
    matches := MatchNamesJaroWinkler(names, target, threshold)
    
    fmt.Println("=== 人名匹配结果 ===")
    for _, match := range matches {
        fmt.Printf("%-20s: %.3f (%s)\n", match.Name, match.Similarity, match.Algorithm)
    }
    
    // 多算法比较
    fmt.Println("\n=== 多算法相似度比较 ===")
    similarities := StringSimilarity("Christopher", "Kristopher")
    for algo, score := range similarities {
        fmt.Printf("%-20s: %.4f\n", algo, score)
    }
}
```

## 2. 拼写纠错 - Levenshtein（加权版）

```go
package main

import (
    "fmt"
    "sort"
    "strings"
    "github.com/texttheater/golang-levenshtein/levenshtein"
)

// 拼写建议结构体
type SpellSuggestion struct {
    Word      string
    Distance  int
    Weighted  float64
    Confidence float64
}

// 标准Levenshtein距离
func SpellCheckLevenshtein(word string, dictionary []string, maxDistance int) []SpellSuggestion {
    var suggestions []SpellSuggestion
    
    for _, dictWord := range dictionary {
        distance := levenshtein.DistanceForStrings(
            []rune(word),
            []rune(dictWord),
            levenshtein.DefaultOptions,
        )
        
        if distance <= maxDistance {
            // 计算置信度（距离越小，置信度越高）
            confidence := 1.0 - float64(distance)/float64(max(len(word), len(dictWord)))
            
            suggestions = append(suggestions, SpellSuggestion{
                Word:      dictWord,
                Distance:  distance,
                Confidence: confidence,
            })
        }
    }
    
    // 按距离升序排序
    sort.Slice(suggestions, func(i, j int) bool {
        if suggestions[i].Distance == suggestions[j].Distance {
            return suggestions[i].Confidence > suggestions[j].Confidence
        }
        return suggestions[i].Distance < suggestions[j].Distance
    })
    
    return suggestions
}

// 加权编辑距离（自定义实现）
type EditWeight struct {
    InsertCost  float64
    DeleteCost  float64
    ReplaceCost float64
    TransposeCost float64 // 相邻字符交换
}

func WeightedLevenshtein(s1, s2 string, weights EditWeight) float64 {
    r1, r2 := []rune(s1), []rune(s2)
    n, m := len(r1), len(r2)
    
    // 初始化DP矩阵
    dp := make([][]float64, n+1)
    for i := range dp {
        dp[i] = make([]float64, m+1)
        dp[i][0] = float64(i) * weights.DeleteCost
    }
    for j := range dp[0] {
        dp[0][j] = float64(j) * weights.InsertCost
    }
    
    // 动态规划计算加权距离
    for i := 1; i <= n; i++ {
        for j := 1; j <= m; j++ {
            if r1[i-1] == r2[j-1] {
                dp[i][j] = dp[i-1][j-1] // 字符相同，无代价
            } else {
                // 替换操作
                replaceCost := dp[i-1][j-1] + weights.ReplaceCost
                
                // 删除操作
                deleteCost := dp[i-1][j] + weights.DeleteCost
                
                // 插入操作
                insertCost := dp[i][j-1] + weights.InsertCost
                
                // 交换操作（Damerau-Levenshtein扩展）
                transposeCost := float64(1<<63 - 1) // 初始化为极大值
                if i > 1 && j > 1 && r1[i-1] == r2[j-2] && r1[i-2] == r2[j-1] {
                    transposeCost = dp[i-2][j-2] + weights.TransposeCost
                }
                
                // 取最小代价
                dp[i][j] = min(replaceCost, deleteCost, insertCost, transposeCost)
            }
        }
    }
    
    return dp[n][m]
}

func min(vals ...float64) float64 {
    minVal := vals[0]
    for _, val := range vals[1:] {
        if val < minVal {
            minVal = val
        }
    }
    return minVal
}

// 智能拼写检查器
type SpellChecker struct {
    Dictionary   []string
    MaxDistance  int
    UseWeighted  bool
    Weights      EditWeight
}

func NewSpellChecker(dictionary []string) *SpellChecker {
    return &SpellChecker{
        Dictionary:  dictionary,
        MaxDistance: 2,
        UseWeighted: true,
        Weights: EditWeight{
            InsertCost:   1.0,
            DeleteCost:   1.0,
            ReplaceCost:  1.0,
            TransposeCost: 0.5, // 相邻字符交换代价较低
        },
    }
}

func (sc *SpellChecker) Correct(word string) []SpellSuggestion {
    var suggestions []SpellSuggestion
    
    for _, dictWord := range sc.Dictionary {
        var distance float64
        var weighted bool
        
        if sc.UseWeighted {
            distance = WeightedLevenshtein(word, dictWord, sc.Weights)
            weighted = true
        } else {
            distance = float64(levenshtein.DistanceForStrings(
                []rune(word),
                []rune(dictWord),
                levenshtein.DefaultOptions,
            ))
            weighted = false
        }
        
        if int(distance) <= sc.MaxDistance {
            // 计算归一化相似度
            maxLen := float64(max(len(word), len(dictWord)))
            confidence := 1.0 - distance/maxLen
            
            suggestions = append(suggestions, SpellSuggestion{
                Word:      dictWord,
                Distance:  int(distance),
                Weighted:  distance,
                Confidence: confidence,
            })
        }
    }
    
    // 按置信度降序排序
    sort.Slice(suggestions, func(i, j int) bool {
        return suggestions[i].Confidence > suggestions[j].Confidence
    })
    
    return suggestions
}

func max(a, b int) int {
    if a > b {
        return a
    }
    return b
}

func main() {
    dictionary := []string{
        "apple", "application", "appliance", "ape", "apply", "banana",
        "computer", "compute", "computation", "compiler",
    }
    
    word := "aplle"
    
    fmt.Println("=== 标准Levenshtein拼写纠正 ===")
    suggestions := SpellCheckLevenshtein(word, dictionary, 2)
    for i, s := range suggestions {
        fmt.Printf("%d. %-15s 距离: %d 置信度: %.2f\n", 
            i+1, s.Word, s.Distance, s.Confidence)
    }
    
    fmt.Println("\n=== 加权编辑距离拼写纠正 ===")
    checker := NewSpellChecker(dictionary)
    weightedSuggestions := checker.Correct(word)
    for i, s := range weightedSuggestions {
        fmt.Printf("%d. %-15s 加权距离: %.2f 置信度: %.2f\n", 
            i+1, s.Word, s.Weighted, s.Confidence)
    }
    
    // 测试相邻字符交换
    fmt.Println("\n=== 相邻字符交换测试 ===")
    pairs := [][2]string{
        {"form", "from"},
        {"teh", "the"},
        {"recieve", "receive"},
    }
    
    for _, pair := range pairs {
        standardDist := levenshtein.DistanceForStrings(
            []rune(pair[0]), []rune(pair[1]), levenshtein.DefaultOptions)
        
        weightedDist := WeightedLevenshtein(pair[0], pair[1], EditWeight{
            InsertCost:   1.0,
            DeleteCost:   1.0,
            ReplaceCost:  1.0,
            TransposeCost: 0.5,
        })
        
        fmt.Printf("%s -> %s: 标准=%d, 加权=%.1f\n", 
            pair[0], pair[1], standardDist, weightedDist)
    }
}
```

## 3. 文档去重 - Jaccard/Sørensen-Dice (n-gram版)

```go
package main

import (
    "fmt"
    "sort"
    "strings"
    "unicode"
)

// NGram 生成器
type NGramGenerator struct {
    N int
}

func NewNGramGenerator(n int) *NGramGenerator {
    return &NGramGenerator{N: n}
}

func (ng *NGramGenerator) Generate(text string) map[string]int {
    // 预处理：转换为小写，移除标点
    text = strings.ToLower(text)
    text = strings.Map(func(r rune) rune {
        if unicode.IsPunct(r) || unicode.IsSpace(r) {
            return ' '
        }
        return r
    }, text)
    
    ngrams := make(map[string]int)
    runes := []rune(text)
    
    for i := 0; i <= len(runes)-ng.N; i++ {
        gram := string(runes[i : i+ng.N])
        // 跳过只包含空格的gram
        if strings.TrimSpace(gram) != "" {
            ngrams[gram]++
        }
    }
    
    return ngrams
}

// 文档相似度计算器
type DocumentSimilarity struct {
    NGramSize int
}

func NewDocumentSimilarity(n int) *DocumentSimilarity {
    return &DocumentSimilarity{NGramSize: n}
}

// Jaccard 相似度
func (ds *DocumentSimilarity) Jaccard(text1, text2 string) float64 {
    gen := NewNGramGenerator(ds.NGramSize)
    ngrams1 := gen.Generate(text1)
    ngrams2 := gen.Generate(text2)
    
    // 计算交集大小
    intersection := 0
    for gram := range ngrams1 {
        if _, exists := ngrams2[gram]; exists {
            intersection++
        }
    }
    
    // 计算并集大小
    union := len(ngrams1) + len(ngrams2) - intersection
    
    if union == 0 {
        return 0.0
    }
    
    return float64(intersection) / float64(union)
}

// Sørensen-Dice 系数
func (ds *DocumentSimilarity) SorensenDice(text1, text2 string) float64 {
    gen := NewNGramGenerator(ds.NGramSize)
    ngrams1 := gen.Generate(text1)
    ngrams2 := gen.Generate(text2)
    
    // 计算交集大小
    intersection := 0
    for gram := range ngrams1 {
        if _, exists := ngrams2[gram]; exists {
            intersection++
        }
    }
    
    // 计算系数
    total := len(ngrams1) + len(ngrams2)
    if total == 0 {
        return 0.0
    }
    
    return 2.0 * float64(intersection) / float64(total)
}

// 重叠系数
func (ds *DocumentSimilarity) OverlapCoefficient(text1, text2 string) float64 {
    gen := NewNGramGenerator(ds.NGramSize)
    ngrams1 := gen.Generate(text1)
    ngrams2 := gen.Generate(text2)
    
    // 计算交集大小
    intersection := 0
    for gram := range ngrams1 {
        if _, exists := ngrams2[gram]; exists {
            intersection++
        }
    }
    
    // 取两个集合的最小大小
    minSize := min(len(ngrams1), len(ngrams2))
    if minSize == 0 {
        return 0.0
    }
    
    return float64(intersection) / float64(minSize)
}

// 文档去重检测
type DuplicateDetector struct {
    Documents []string
    Threshold float64
    Algorithm string // "jaccard", "sorensen", "overlap"
}

func NewDuplicateDetector(docs []string, threshold float64) *DuplicateDetector {
    return &DuplicateDetector{
        Documents: docs,
        Threshold: threshold,
        Algorithm: "jaccard",
    }
}

func (dd *DuplicateDetector) FindDuplicates() []map[string]interface{} {
    ds := NewDocumentSimilarity(3) // 使用3-gram
    var duplicates []map[string]interface{}
    
    for i := 0; i < len(dd.Documents); i++ {
        for j := i + 1; j < len(dd.Documents); j++ {
            var similarity float64
            
            switch dd.Algorithm {
            case "jaccard":
                similarity = ds.Jaccard(dd.Documents[i], dd.Documents[j])
            case "sorensen":
                similarity = ds.SorensenDice(dd.Documents[i], dd.Documents[j])
            case "overlap":
                similarity = ds.OverlapCoefficient(dd.Documents[i], dd.Documents[j])
            default:
                similarity = ds.Jaccard(dd.Documents[i], dd.Documents[j])
            }
            
            if similarity >= dd.Threshold {
                duplicates = append(duplicates, map[string]interface{}{
                    "doc1_index": i,
                    "doc2_index": j,
                    "similarity": similarity,
                    "algorithm":  dd.Algorithm,
                    "snippet1":   truncateString(dd.Documents[i], 50),
                    "snippet2":   truncateString(dd.Documents[j], 50),
                })
            }
        }
    }
    
    // 按相似度降序排序
    sort.Slice(duplicates, func(i, j int) bool {
        return duplicates[i]["similarity"].(float64) > duplicates[j]["similarity"].(float64)
    })
    
    return duplicates
}

func truncateString(s string, length int) string {
    if len(s) <= length {
        return s
    }
    return s[:length] + "..."
}

// 大规模文档去重（MinHash近似算法）
type MinHash struct {
    NumHashes int
    HashFuncs []func(string) uint64
}

func NewMinHash(numHashes int) *MinHash {
    mh := &MinHash{
        NumHashes: numHashes,
        HashFuncs: make([]func(string) uint64, numHashes),
    }
    
    // 初始化哈希函数（简化版）
    for i := 0; i < numHashes; i++ {
        seed := uint64(i * 10007) // 简单种子
        mh.HashFuncs[i] = func(s string) uint64 {
            h := seed
            for _, r := range s {
                h = h*31 + uint64(r)
            }
            return h
        }
    }
    
    return mh
}

func (mh *MinHash) Signature(text string, n int) []uint64 {
    gen := NewNGramGenerator(n)
    ngrams := gen.Generate(text)
    
    signature := make([]uint64, mh.NumHashes)
    for i := range signature {
        signature[i] = ^uint64(0) // 最大值
    }
    
    // 为每个n-gram计算哈希值并取最小值
    for gram := range ngrams {
        for i, hashFunc := range mh.HashFuncs {
            hashValue := hashFunc(gram)
            if hashValue < signature[i] {
                signature[i] = hashValue
            }
        }
    }
    
    return signature
}

func (mh *MinHash) Similarity(sig1, sig2 []uint64) float64 {
    if len(sig1) != len(sig2) {
        return 0.0
    }
    
    matches := 0
    for i := 0; i < len(sig1); i++ {
        if sig1[i] == sig2[i] {
            matches++
        }
    }
    
    return float64(matches) / float64(len(sig1))
}

func main() {
    documents := []string{
        "The quick brown fox jumps over the lazy dog",
        "A quick brown fox jumps over the lazy dog",
        "The fast brown fox jumps over the sleepy dog",
        "完全不同的句子，不会有相似度",
        "The quick brown fox jumps over lazy dog",
        "The quick brown fox jumps over the lazy dog. This is a classic sentence.",
    }
    
    fmt.Println("=== 文档去重检测 (Jaccard) ===")
    detector := NewDuplicateDetector(documents, 0.5)
    detector.Algorithm = "jaccard"
    duplicates := detector.FindDuplicates()
    
    for _, dup := range duplicates {
        fmt.Printf("文档%d ≈ 文档%d: %.3f\n", 
            dup["doc1_index"].(int), dup["doc2_index"].(int), dup["similarity"].(float64))
        fmt.Printf("  片段1: %s\n", dup["snippet1"].(string))
        fmt.Printf("  片段2: %s\n\n", dup["snippet2"].(string))
    }
    
    fmt.Println("=== 不同算法比较 ===")
    ds := NewDocumentSimilarity(3)
    text1 := "hello world"
    text2 := "world hello"
    
    fmt.Printf("Jaccard: %.3f\n", ds.Jaccard(text1, text2))
    fmt.Printf("Sørensen-Dice: %.3f\n", ds.SorensenDice(text1, text2))
    fmt.Printf("Overlap: %.3f\n", ds.OverlapCoefficient(text1, text2))
    
    fmt.Println("\n=== MinHash大规模去重 ===")
    mh := NewMinHash(128)
    sig1 := mh.Signature(documents[0], 2)
    sig2 := mh.Signature(documents[1], 2)
    fmt.Printf("MinHash相似度: %.3f\n", mh.Similarity(sig1, sig2))
}
```

## 4. 基因序列/抄袭检测 - Smith-Waterman-Gotoh

```go
package main

import (
    "fmt"
    "math"
)

// Smith-Waterman 局部序列比对
type SmithWaterman struct {
    MatchScore      float64
    MismatchPenalty float64
    GapOpenPenalty  float64
    GapExtendPenalty float64
}

func NewSmithWaterman() *SmithWaterman {
    return &SmithWaterman{
        MatchScore:      2.0,
        MismatchPenalty: -1.0,
        GapOpenPenalty:  -0.5,
        GapExtendPenalty: -0.1,
    }
}

// 局部序列比对（简化版）
func (sw *SmithWaterman) Align(seq1, seq2 string) (float64, string, string) {
    m, n := len(seq1), len(seq2)
    
    // 初始化得分矩阵
    score := make([][]float64, m+1)
    for i := range score {
        score[i] = make([]float64, n+1)
    }
    
    // 初始化回溯指针
    traceback := make([][]int, m+1)
    for i := range traceback {
        traceback[i] = make([]int, n+1)
    }
    
    maxScore := 0.0
    maxI, maxJ := 0, 0
    
    // 填充得分矩阵
    for i := 1; i <= m; i++ {
        for j := 1; j <= n; j++ {
            // 匹配/不匹配得分
            var matchScore float64
            if seq1[i-1] == seq2[j-1] {
                matchScore = sw.MatchScore
            } else {
                matchScore = sw.MismatchPenalty
            }
            
            // 可能的得分来源
            diagonal := score[i-1][j-1] + matchScore
            up := score[i-1][j] + sw.GapExtendPenalty
            left := score[i][j-1] + sw.GapExtendPenalty
            
            // 取最大值，不小于0
            score[i][j] = math.Max(0, math.Max(diagonal, math.Max(up, left)))
            
            // 记录最大值位置
            if score[i][j] > maxScore {
                maxScore = score[i][j]
                maxI, maxJ = i, j
            }
            
            // 设置回溯指针
            if score[i][j] == 0 {
                traceback[i][j] = 0 // 结束
            } else if score[i][j] == diagonal {
                traceback[i][j] = 1 // 对角
            } else if score[i][j] == up {
                traceback[i][j] = 2 // 上方
            } else {
                traceback[i][j] = 3 // 左方
            }
        }
    }
    
    // 回溯构建比对结果
    aligned1, aligned2 := "", ""
    i, j := maxI, maxJ
    
    for traceback[i][j] != 0 {
        switch traceback[i][j] {
        case 1: // 对角
            aligned1 = string(seq1[i-1]) + aligned1
            aligned2 = string(seq2[j-1]) + aligned2
            i--
            j--
        case 2: // 上方（seq1缺失）
            aligned1 = string(seq1[i-1]) + aligned1
            aligned2 = "-" + aligned2
            i--
        case 3: // 左方（seq2缺失）
            aligned1 = "-" + aligned1
            aligned2 = string(seq2[j-1]) + aligned2
            j--
        }
    }
    
    return maxScore, aligned1, aligned2
}

// 抄袭检测器
type PlagiarismDetector struct {
    MinMatchLength int
    SimilarityThreshold float64
}

func NewPlagiarismDetector() *PlagiarismDetector {
    return &PlagiarismDetector{
        MinMatchLength:     10,
        SimilarityThreshold: 0.7,
    }
}

// 滑动窗口检测
func (pd *PlagiarismDetector) Detect(text1, text2 string) []map[string]interface{} {
    var matches []map[string]interface{}
    sw := NewSmithWaterman()
    
    // 将文本分割成重叠的片段
    segmentLength := 50
    overlap := 25
    
    segments1 := pd.createSegments(text1, segmentLength, overlap)
    segments2 := pd.createSegments(text2, segmentLength, overlap)
    
    for i, seg1 := range segments1 {
        for j, seg2 := range segments2 {
            if len(seg1) >= pd.MinMatchLength && len(seg2) >= pd.MinMatchLength {
                score, aligned1, aligned2 := sw.Align(seg1, seg2)
                
                // 计算归一化相似度
                maxLength := float64(max(len(seg1), len(seg2)))
                normalizedScore := score / (maxLength * sw.MatchScore)
                
                if normalizedScore >= pd.SimilarityThreshold {
                    matches = append(matches, map[string]interface{}{
                        "segment1":       seg1,
                        "segment2":       seg2,
                        "score":          score,
                        "normalized":     normalizedScore,
                        "aligned1":       aligned1,
                        "aligned2":       aligned2,
                        "position1":      i * overlap,
                        "position2":      j * overlap,
                        "alignment_length": len(aligned1),
                    })
                }
            }
        }
    }
    
    return matches
}

func (pd *PlagiarismDetector) createSegments(text string, length, overlap int) []string {
    var segments []string
    runes := []rune(text)
    
    for i := 0; i < len(runes)-length+1; i += overlap {
        end := i + length
        if end > len(runes) {
            end = len(runes)
        }
        segments = append(segments, string(runes[i:end]))
    }
    
    return segments
}

// 基因序列比对
func AlignDNA(seq1, seq2 string) {
    sw := NewSmithWaterman()
    sw.MatchScore = 1.0
    sw.MismatchPenalty = -2.0
    sw.GapOpenPenalty = -2.0
    sw.GapExtendPenalty = -1.0
    
    score, aligned1, aligned2 := sw.Align(seq1, seq2)
    
    fmt.Println("DNA序列比对:")
    fmt.Println("序列1:", aligned1)
    fmt.Println("序列2:", aligned2)
    fmt.Printf("比对分数: %.2f\n", score)
    fmt.Printf("相似度: %.2f%%\n", 
        float64(countMatches(aligned1, aligned2))/float64(len(aligned1))*100)
}

func countMatches(s1, s2 string) int {
    count := 0
    minLen := min(len(s1), len(s2))
    for i := 0; i < minLen; i++ {
        if s1[i] == s2[i] && s1[i] != '-' {
            count++
        }
    }
    return count
}

func main() {
    // 示例：基因序列比对
    fmt.Println("=== 基因序列比对 ===")
    dna1 := "GATTACA"
    dna2 := "GCATGCU"
    AlignDNA(dna1, dna2)
    
    // 示例：抄袭检测
    fmt.Println("\n=== 抄袭检测 ===")
    text1 := `This is a sample text for testing plagiarism detection algorithm. 
    It contains some unique phrases and sentences that might be copied.`
    
    text2 := `This sample text is for testing the plagiarism detection method.
    It has some similar phrases and sentences that could be identified.`
    
    detector := NewPlagiarismDetector()
    matches := detector.Detect(text1, text2)
    
    fmt.Printf("发现 %d 个相似片段:\n", len(matches))
    for i, match := range matches {
        fmt.Printf("\n片段 %d (相似度: %.2f):\n", i+1, match["normalized"].(float64))
        fmt.Printf("  文本1[%d]: %s\n", match["position1"].(int), 
            truncateString(match["segment1"].(string), 50))
        fmt.Printf("  文本2[%d]: %s\n", match["position2"].(int), 
            truncateString(match["segment2"].(string), 50))
    }
}
```

## 5. 短文本相似度 - 重叠系数 + Jaccard组合

```go
package main

import (
    "fmt"
    "sort"
    "strings"
)

// 短文本相似度计算器
type ShortTextSimilarity struct {
    UseCombination bool
    NGramSize      int
}

func NewShortTextSimilarity() *ShortTextSimilarity {
    return &ShortTextSimilarity{
        UseCombination: true,
        NGramSize:      2,
    }
}

// 分词函数
func tokenize(text string) map[string]bool {
    tokens := make(map[string]bool)
    words := strings.Fields(strings.ToLower(text))
    for _, word := range words {
        tokens[word] = true
    }
    return tokens
}

// 重叠系数
func overlapCoefficient(tokens1, tokens2 map[string]bool) float64 {
    intersection := 0
    for token := range tokens1 {
        if tokens2[token] {
            intersection++
        }
    }
    
    minSize := min(len(tokens1), len(tokens2))
    if minSize == 0 {
        return 0.0
    }
    
    return float64(intersection) / float64(minSize)
}

// Jaccard系数
func jaccardCoefficient(tokens1, tokens2 map[string]bool) float64 {
    intersection := 0
    union := len(tokens1)
    
    // 计算交集
    for token := range tokens1 {
        if tokens2[token] {
            intersection++
        }
    }
    
    // 计算并集
    for token := range tokens2 {
        if !tokens1[token] {
            union++
        }
    }
    
    if union == 0 {
        return 0.0
    }
    
    return float64(intersection) / float64(union)
}

// 计算短文本相似度
func (sts *ShortTextSimilarity) Calculate(text1, text2 string) map[string]float64 {
    tokens1 := tokenize(text1)
    tokens2 := tokenize(text2)
    
    overlap := overlapCoefficient(tokens1, tokens2)
    jaccard := jaccardCoefficient(tokens1, tokens2)
    
    result := map[string]float64{
        "overlap":  overlap,
        "jaccard":  jaccard,
    }
    
    if sts.UseCombination {
        // 组合策略：加权平均
        // 可以根据场景调整权重
        combined := 0.4*overlap + 0.6*jaccard
        result["combined"] = combined
    }
    
    return result
}

// 短文本搜索引擎
type ShortTextSearch struct {
    Texts      []string
    Threshold  float64
    Similarity *ShortTextSimilarity
}

func NewShortTextSearch(texts []string) *ShortTextSearch {
    return &ShortTextSearch{
        Texts:      texts,
        Threshold:  0.3,
        Similarity: NewShortTextSimilarity(),
    }
}

func (sts *ShortTextSearch) Search(query string) []map[string]interface{} {
    var results []map[string]interface{}
    
    for i, text := range sts.Texts {
        similarity := sts.Similarity.Calculate(query, text)
        combinedScore := similarity["combined"]
        
        if combinedScore >= sts.Threshold {
            results = append(results, map[string]interface{}{
                "index":      i,
                "text":       text,
                "similarity": combinedScore,
                "details":    similarity,
            })
        }
    }
    
    // 按相似度降序排序
    sort.Slice(results, func(i, j int) bool {
        return results[i]["similarity"].(float64) > results[j]["similarity"].(float64)
    })
    
    return results
}

// N-gram相似度计算
func ngramSimilarity(text1, text2 string, n int) map[string]float64 {
    // 生成n-gram集合
    ngrams1 := generateNGrams(text1, n)
    ngrams2 := generateNGrams(text2, n)
    
    // 计算各种系数
    result := make(map[string]float64)
    
    // Jaccard
    intersection := 0
    for gram := range ngrams1 {
        if ngrams2[gram] {
            intersection++
        }
    }
    
    union := len(ngrams1) + len(ngrams2) - intersection
    if union > 0 {
        result["jaccard"] = float64(intersection) / float64(union)
    }
    
    // Sørensen-Dice
    total := len(ngrams1) + len(ngrams2)
    if total > 0 {
        result["sorensen"] = 2.0 * float64(intersection) / float64(total)
    }
    
    // Overlap
    minSize := min(len(ngrams1), len(ngrams2))
    if minSize > 0 {
        result["overlap"] = float64(intersection) / float64(minSize)
    }
    
    return result
}

func generateNGrams(text string, n int) map[string]bool {
    text = strings.ToLower(text)
    ngrams := make(map[string]bool)
    
    runes := []rune(text)
    for i := 0; i <= len(runes)-n; i++ {
        gram := string(runes[i : i+n])
        if strings.TrimSpace(gram) != "" {
            ngrams[gram] = true
        }
    }
    
    return ngrams
}

func main() {
    fmt.Println("=== 短文本相似度计算 ===")
    
    query := "quick brown fox"
    texts := []string{
        "brown fox quick",
        "quick brown dog",
        "fast brown fox",
        "the quick brown fox jumps",
        "completely different",
        "quick and brown fox running",
    }
    
    // 创建搜索引擎
    searcher := NewShortTextSearch(texts)
    results := searcher.Search(query)
    
    fmt.Printf("查询: \"%s\"\n\n", query)
    fmt.Println("匹配结果:")
    for i, result := range results {
        fmt.Printf("%d. %-40s 相似度: %.3f\n", 
            i+1, 
            truncateString(result["text"].(string), 35),
            result["similarity"].(float64))
        
        details := result["details"].(map[string]float64)
        fmt.Printf("   细节: Overlap=%.3f, Jaccard=%.3f\n", 
            details["overlap"], details["jaccard"])
    }
    
    fmt.Println("\n=== N-gram相似度比较 ===")
    text1 := "hello world"
    text2 := "world hello"
    
    for n := 1; n <= 3; n++ {
        similarities := ngramSimilarity(text1, text2, n)
        fmt.Printf("\n%d-gram 相似度:\n", n)
        for algo, score := range similarities {
            fmt.Printf("  %-12s: %.3f\n", algo, score)
        }
    }
    
    // 测试不同组合策略
    fmt.Println("\n=== 不同相似度组合策略 ===")
    testPairs := [][2]string{
        {"cat dog", "dog cat"},
        {"apple pie", "apple tart"},
        {"machine learning", "deep learning"},
        {"go programming", "python programming"},
    }
    
    for _, pair := range testPairs {
        tokens1 := tokenize(pair[0])
        tokens2 := tokenize(pair[1])
        
        overlap := overlapCoefficient(tokens1, tokens2)
        jaccard := jaccardCoefficient(tokens1, tokens2)
        
        // 不同组合方式
        avg := (overlap + jaccard) / 2
        weighted := 0.3*overlap + 0.7*jaccard // 更注重整体相似度
        maxVal := math.Max(overlap, jaccard)  // 取最大值
        
        fmt.Printf("\n\"%s\" vs \"%s\":\n", pair[0], pair[1])
        fmt.Printf("  Overlap: %.3f, Jaccard: %.3f\n", overlap, jaccard)
        fmt.Printf("  平均值: %.3f, 加权: %.3f, 最大值: %.3f\n", avg, weighted, maxVal)
    }
}
```

## 6. 编码/哈希校验 - Hamming距离

```go
package main

import (
    "fmt"
    "hash/crc32"
    "hash/fnv"
)

// Hamming距离计算
func HammingDistance(s1, s2 string) (int, error) {
    if len(s1) != len(s2) {
        return 0, fmt.Errorf("字符串长度不相等: %d != %d", len(s1), len(s2))
    }
    
    distance := 0
    for i := 0; i < len(s1); i++ {
        if s1[i] != s2[i] {
            distance++
        }
    }
    
    return distance, nil
}

// 二进制字符串的Hamming距离
func BinaryHammingDistance(bin1, bin2 string) (int, error) {
    if len(bin1) != len(bin2) {
        return 0, fmt.Errorf("二进制字符串长度不相等")
    }
    
    distance := 0
    for i := 0; i < len(bin1); i++ {
        if bin1[i] != bin2[i] {
            distance++
        }
    }
    
    return distance, nil
}

// Hamming距离详细分析
func AnalyzeHamming(s1, s2 string) map[string]interface{} {
    result := make(map[string]interface{})
    
    if len(s1) != len(s2) {
        result["error"] = "字符串长度不相等"
        return result
    }
    
    distance, _ := HammingDistance(s1, s2)
    length := len(s1)
    
    result["distance"] = distance
    result["length"] = length
    result["similarity_percent"] = float64(length-distance) / float64(length) * 100
    result["error_rate"] = float64(distance) / float64(length)
    result["is_perfect_match"] = distance == 0
    result["bits_per_error"] = float64(length) / float64(distance) if distance > 0 else 0
    
    return result
}

// 错误检测码示例
type ErrorDetectionCode struct {
    Data string
    ParityBits int
}

func (edc *ErrorDetectionCode) AddParity() string {
    // 简化的奇偶校验
    ones := 0
    for _, bit := range edc.Data {
        if bit == '1' {
            ones++
        }
    }
    
    parity := '0'
    if ones%2 == 1 {
        parity = '1'
    }
    
    return edc.Data + string(parity)
}

func (edc *ErrorDetectionCode) CheckParity(dataWithParity string) bool {
    if len(dataWithParity) <= edc.ParityBits {
        return false
    }
    
    data := dataWithParity[:len(dataWithParity)-edc.ParityBits]
    parity := dataWithParity[len(dataWithParity)-edc.ParityBits:]
    
    // 计算数据的奇偶性
    ones := 0
    for _, bit := range data {
        if bit == '1' {
            ones++
        }
    }
    
    expectedParity := "0"
    if ones%2 == 1 {
        expectedParity = "1"
    }
    
    return parity == expectedParity
}

// 哈希校验
type HashValidator struct {
    HashFunc func(string) uint32
}

func NewHashValidator() *HashValidator {
    return &HashValidator{
        HashFunc: func(s string) uint32 {
            h := fnv.New32a()
            h.Write([]byte(s))
            return h.Sum32()
        },
    }
}

func (hv *HashValidator) Validate(data string, expectedHash uint32) bool {
    actualHash := hv.HashFunc(data)
    return actualHash == expectedHash
}

func (hv *HashValidator) ValidateWithHamming(data string, expectedHash uint32, maxErrors int) (bool, int) {
    actualHash := hv.HashFunc(data)
    
    if actualHash == expectedHash {
        return true, 0
    }
    
    // 转换为二进制字符串比较
    actualBin := fmt.Sprintf("%032b", actualHash)
    expectedBin := fmt.Sprintf("%032b", expectedHash)
    
    distance, err := BinaryHammingDistance(actualBin, expectedBin)
    if err != nil {
        return false, -1
    }
    
    return distance <= maxErrors, distance
}

// DNA序列突变检测
func DNASequenceAnalysis(dna1, dna2 string) {
    if len(dna1) != len(dna2) {
        fmt.Println("DNA序列长度不同")
        return
    }
    
    distance, _ := HammingDistance(dna1, dna2)
    length := len(dna1)
    
    fmt.Printf("DNA序列分析:\n")
    fmt.Printf("  序列1: %s\n", dna1)
    fmt.Printf("  序列2: %s\n", dna2)
    fmt.Printf("  长度: %d\n", length)
    fmt.Printf("  Hamming距离: %d\n", distance)
    fmt.Printf("  突变率: %.2f%%\n", float64(distance)/float64(length)*100)
    
    // 分析突变类型
    transitions := 0 // 嘌呤<->嘌呤 或 嘧啶<->嘧啶
    transversions := 0 // 嘌呤<->嘧啶
    
    for i := 0; i < length; i++ {
        if dna1[i] != dna2[i] {
            b1, b2 := dna1[i], dna2[i]
            
            // 判断转换类型
            if (isPurine(b1) && isPurine(b2)) || (isPyrimidine(b1) && isPyrimidine(b2)) {
                transitions++
            } else {
                transversions++
            }
        }
    }
    
    if distance > 0 {
        fmt.Printf("  转换突变: %d (%.1f%%)\n", transitions, 
            float64(transitions)/float64(distance)*100)
        fmt.Printf("  颠换突变: %d (%.1f%%)\n", transversions,
            float64(transversions)/float64(distance)*100)
    }
}

func isPurine(b byte) bool {
    return b == 'A' || b == 'G'
}

func isPyrimidine(b byte) bool {
    return b == 'C' || b == 'T' || b == 'U'
}

func main() {
    fmt.Println("=== Hamming距离示例 ===")
    
    // 基础Hamming距离
    code1 := "10101010"
    code2 := "10101011"
    
    distance, err := HammingDistance(code1, code2)
    if err != nil {
        fmt.Println("错误:", err)
    } else {
        fmt.Printf("Hamming距离: %d\n", distance)
        analysis := AnalyzeHamming(code1, code2)
        fmt.Printf("分析结果: %+v\n", analysis)
    }
    
    // 奇偶校验
    fmt.Println("\n=== 奇偶校验示例 ===")
    edc := &ErrorDetectionCode{Data: "1011001", ParityBits: 1}
    withParity := edc.AddParity()
    fmt.Printf("原始数据: %s\n", edc.Data)
    fmt.Printf("带校验位: %s\n", withParity)
    fmt.Printf("校验结果: %v\n", edc.CheckParity(withParity))
    
    // 测试错误检测
    corrupted := "10110010" // 最后一位错误
    fmt.Printf("错误数据校验: %v\n", edc.CheckParity(corrupted))
    
    // 哈希校验
    fmt.Println("\n=== 哈希校验示例 ===")
    validator := NewHashValidator()
    data := "important data"
    expectedHash := validator.HashFunc(data)
    
    // 正常校验
    fmt.Printf("数据: %s\n", data)
    fmt.Printf("期望哈希: %d\n", expectedHash)
    fmt.Printf("校验结果: %v\n", validator.Validate(data, expectedHash))
    
    // 带错误容忍的校验
    corruptedData := "important datb"
    isValid, dist := validator.ValidateWithHamming(corruptedData, expectedHash, 2)
    fmt.Printf("损坏数据校验: 有效=%v, Hamming距离=%d\n", isValid, dist)
    
    // DNA序列分析
    fmt.Println("\n=== DNA序列突变分析 ===")
    dna1 := "AGCTAGCTAGCT"
    dna2 := "AGCTAGCAAGCT"
    DNASequenceAnalysis(dna1, dna2)
    
    // CRC校验示例
    fmt.Println("\n=== CRC校验示例 ===")
    crcTable := crc32.MakeTable(crc32.IEEE)
    crc := crc32.Checksum([]byte(data), crcTable)
    fmt.Printf("CRC32校验和: %d (0x%08x)\n", crc, crc)
    
    // 传输错误模拟
    fmt.Println("\n=== 传输错误模拟 ===")
    transmitted := "1010101010101010"
    received := "1010101010101011" // 最后一位错误
    
    dist, _ = HammingDistance(transmitted, received)
    fmt.Printf("传输: %s\n", transmitted)
    fmt.Printf("接收: %s\n", received)
    fmt.Printf("错误位数: %d\n", dist)
    
    // 错误纠正能力分析
    codeLength := len(transmitted)
    maxCorrectable := (dist - 1) / 2
    fmt.Printf("编码长度: %d bits\n", codeLength)
    fmt.Printf("可纠正最大错误: %d bits\n", maxCorrectable)
    fmt.Printf("错误检测能力: %d bits\n", dist-1)
}
```

## 7. 推荐系统相似度 - Cosine相似度

```go
package main

import (
    "fmt"
    "math"
    "sort"
    "strings"
)

// 向量余弦相似度
func CosineSimilarity(vec1, vec2 []float64) float64 {
    if len(vec1) != len(vec2) {
        return 0.0
    }
    
    dotProduct := 0.0
    norm1 := 0.0
    norm2 := 0.0
    
    for i := 0; i < len(vec1); i++ {
        dotProduct += vec1[i] * vec2[i]
        norm1 += vec1[i] * vec1[i]
        norm2 += vec2[i] * vec2[i]
    }
    
    if norm1 == 0 || norm2 == 0 {
        return 0.0
    }
    
    return dotProduct / (math.Sqrt(norm1) * math.Sqrt(norm2))
}

// 文本余弦相似度
type TextCosineSimilarity struct {
    UseTFIDF     bool
    IDF          map[string]float64
    Vocabulary   []string
}

func NewTextCosineSimilarity() *TextCosineSimilarity {
    return &TextCosineSimilarity{
        UseTFIDF: false,
        IDF:      make(map[string]float64),
    }
}

// 构建词频向量
func (tcs *TextCosineSimilarity) TextToVector(text string) []float64 {
    words := strings.Fields(strings.ToLower(text))
    wordFreq := make(map[string]float64)
    
    // 计算词频
    for _, word := range words {
        wordFreq[word]++
    }
    
    // 构建向量
    var vector []float64
    if tcs.Vocabulary == nil {
        // 如果没有预定义词汇表，使用文本中的词汇
        for _, freq := range wordFreq {
            vector = append(vector, freq)
        }
    } else {
        // 使用预定义词汇表
        vector = make([]float64, len(tcs.Vocabulary))
        for i, word := range tcs.Vocabulary {
            vector[i] = wordFreq[word]
        }
    }
    
    return vector
}

// 计算文本余弦相似度
func (tcs *TextCosineSimilarity) Similarity(text1, text2 string) float64 {
    vec1 := tcs.TextToVector(text1)
    vec2 := tcs.TextToVector(text2)
    
    // 确保向量长度相同
    maxLen := max(len(vec1), len(vec2))
    if len(vec1) < maxLen {
        vec1 = append(vec1, make([]float64, maxLen-len(vec1))...)
    }
    if len(vec2) < maxLen {
        vec2 = append(vec2, make([]float64, maxLen-len(vec2))...)
    }
    
    return CosineSimilarity(vec1, vec2)
}

// 推荐系统
type RecommendationSystem struct {
    Items      map[string][]float64 // 物品特征向量
    UserPrefs  map[string][]float64 // 用户偏好向量
}

func NewRecommendationSystem() *RecommendationSystem {
    return &RecommendationSystem{
        Items:     make(map[string][]float64),
        UserPrefs: make(map[string][]float64),
    }
}

// 添加物品
func (rs *RecommendationSystem) AddItem(itemID string, features []float64) {
    rs.Items[itemID] = features
}

// 添加用户偏好
func (rs *RecommendationSystem) AddUserPreference(userID string, preferences []float64) {
    rs.UserPrefs[userID] = preferences
}

// 为用户推荐物品
func (rs *RecommendationSystem) RecommendForUser(userID string, topN int) []map[string]interface{} {
    userPref, exists := rs.UserPrefs[userID]
    if !exists {
        return nil
    }
    
    var recommendations []map[string]interface{}
    
    for itemID, itemFeatures := range rs.Items {
        similarity := CosineSimilarity(userPref, itemFeatures)
        
        recommendations = append(recommendations, map[string]interface{}{
            "item_id":    itemID,
            "similarity": similarity,
            "features":   itemFeatures,
        })
    }
    
    // 按相似度降序排序
    sort.Slice(recommendations, func(i, j int) bool {
        return recommendations[i]["similarity"].(float64) > recommendations[j]["similarity"].(float64)
    })
    
    // 返回topN个推荐
    if topN > 0 && topN < len(recommendations) {
        return recommendations[:topN]
    }
    
    return recommendations
}

// 查找相似物品
func (rs *RecommendationSystem) FindSimilarItems(itemID string, topN int) []map[string]interface{} {
    targetFeatures, exists := rs.Items[itemID]
    if !exists {
        return nil
    }
    
    var similarItems []map[string]interface{}
    
    for otherID, otherFeatures := range rs.Items {
        if otherID == itemID {
            continue
        }
        
        similarity := CosineSimilarity(targetFeatures, otherFeatures)
        
        similarItems = append(similarItems, map[string]interface{}{
            "item_id":    otherID,
            "similarity": similarity,
        })
    }
    
    // 按相似度降序排序
    sort.Slice(similarItems, func(i, j int) bool {
        return similarItems[i]["similarity"].(float64) > similarItems[j]["similarity"].(float64)
    })
    
    // 返回topN个相似物品
    if topN > 0 && topN < len(similarItems) {
        return similarItems[:topN]
    }
    
    return similarItems
}

// 协同过滤（基于用户的协同过滤）
func (rs *RecommendationSystem) CollaborativeFiltering(userID string, topN int) []map[string]interface{} {
    targetUserPref, exists := rs.UserPrefs[userID]
    if !exists {
        return nil
    }
    
    // 计算用户相似度
    var userSimilarities []map[string]interface{}
    
    for otherUserID, otherUserPref := range rs.UserPrefs {
        if otherUserID == userID {
            continue
        }
        
        similarity := CosineSimilarity(targetUserPref, otherUserPref)
        
        userSimilarities = append(userSimilarities, map[string]interface{}{
            "user_id":    otherUserID,
            "similarity": similarity,
        })
    }
    
    // 按相似度降序排序
    sort.Slice(userSimilarities, func(i, j int) bool {
        return userSimilarities[i]["similarity"].(float64) > userSimilarities[j]["similarity"].(float64)
    })
    
    // 基于相似用户的喜好推荐物品
    // 这里简化处理：返回相似用户喜欢的物品
    recommendations := make(map[string]float64)
    
    // 取最相似的K个用户
    k := min(3, len(userSimilarities))
    for i := 0; i < k; i++ {
        similarUser := userSimilarities[i]
        similarUserID := similarUser["user_id"].(string)
        weight := similarUser["similarity"].(float64)
        
        // 获取相似用户喜欢的物品（这里简化：假设用户偏好向量就是物品评分）
        userPref := rs.UserPrefs[similarUserID]
        
        // 找到用户评分高的物品
        for itemID, rating := range userPref {
            if rating > 0 {
                recommendations[itemID] += rating * weight
            }
        }
    }
    
    // 转换为推荐列表
    var recommendationList []map[string]interface{}
    for itemID, score := range recommendations {
        recommendationList = append(recommendationList, map[string]interface{}{
            "item_id": itemID,
            "score":   score,
        })
    }
    
    // 按得分降序排序
    sort.Slice(recommendationList, func(i, j int) bool {
        return recommendationList[i]["score"].(float64) > recommendationList[j]["score"].(float64)
    })
    
    // 返回topN个推荐
    if topN > 0 && topN < len(recommendationList) {
        return recommendationList[:topN]
    }
    
    return recommendationList
}

// TF-IDF向量化
type TFIDFVectorizer struct {
    Vocabulary   []string
    IDF          map[string]float64
    Documents    []string
}

func NewTFIDFVectorizer(documents []string) *TFIDFVectorizer {
    vectorizer := &TFIDFVectorizer{
        Documents: documents,
        IDF:       make(map[string]float64),
    }
    
    vectorizer.buildVocabulary()
    vectorizer.calculateIDF()
    
    return vectorizer
}

func (tv *TFIDFVectorizer) buildVocabulary() {
    wordSet := make(map[string]bool)
    
    for _, doc := range tv.Documents {
        words := strings.Fields(strings.ToLower(doc))
        for _, word := range words {
            wordSet[word] = true
        }
    }
    
    for word := range wordSet {
        tv.Vocabulary = append(tv.Vocabulary, word)
    }
    
    sort.Strings(tv.Vocabulary)
}

func (tv *TFIDFVectorizer) calculateIDF() {
    totalDocs := float64(len(tv.Documents))
    
    for _, word := range tv.Vocabulary {
        docCount := 0
        for _, doc := range tv.Documents {
            words := strings.Fields(strings.ToLower(doc))
            for _, w := range words {
                if w == word {
                    docCount++
                    break
                }
            }
        }
        
        // IDF公式: log((N+1)/(df+1)) + 1
        tv.IDF[word] = math.Log((totalDocs+1)/(float64(docCount)+1)) + 1
    }
}

func (tv *TFIDFVectorizer) Transform(text string) []float64 {
    words := strings.Fields(strings.ToLower(text))
    termFreq := make(map[string]float64)
    
    // 计算词频
    for _, word := range words {
        termFreq[word]++
    }
    
    // 归一化词频
    totalTerms := float64(len(words))
    for word := range termFreq {
        termFreq[word] /= totalTerms
    }
    
    // 构建TF-IDF向量
    vector := make([]float64, len(tv.Vocabulary))
    for i, word := range tv.Vocabulary {
        tf := termFreq[word]
        idf := tv.IDF[word]
        vector[i] = tf * idf
    }
    
    return vector
}

func main() {
    fmt.Println("=== 余弦相似度示例 ===")
    
    // 基础余弦相似度
    vec1 := []float64{1, 2, 3, 4, 5}
    vec2 := []float64{1, 2, 3, 4, 5}
    vec3 := []float64{5, 4, 3, 2, 1}
    
    fmt.Printf("向量1和2的余弦相似度: %.3f\n", CosineSimilarity(vec1, vec2))
    fmt.Printf("向量1和3的余弦相似度: %.3f\n", CosineSimilarity(vec1, vec3))
    
    // 文本余弦相似度
    fmt.Println("\n=== 文本余弦相似度 ===")
    tcs := NewTextCosineSimilarity()
    
    text1 := "machine learning artificial intelligence"
    text2 := "artificial intelligence deep learning"
    text3 := "computer science algorithms"
    
    fmt.Printf("文本1: %s\n", text1)
    fmt.Printf("文本2: %s\n", text2)
    fmt.Printf("相似度: %.3f\n", tcs.Similarity(text1, text2))
    
    fmt.Printf("\n文本1: %s\n", text1)
    fmt.Printf("文本3: %s\n", text3)
    fmt.Printf("相似度: %.3f\n", tcs.Similarity(text1, text3))
    
    // 推荐系统示例
    fmt.Println("\n=== 推荐系统示例 ===")
    rs := NewRecommendationSystem()
    
    // 定义物品特征（假设有5个特征维度）
    items := map[string][]float64{
        "item1": {2, 1, 3, 0, 1},  // 科技类，教育性强
        "item2": {0, 0, 1, 2, 3},  // 娱乐类，轻松愉快
        "item3": {1, 2, 2, 1, 0},  // 平衡型
        "item4": {3, 0, 1, 0, 2},  // 科技类，有一定娱乐性
        "item5": {0, 3, 0, 2, 1},  // 娱乐类，有教育意义
    }
    
    // 添加物品
    for itemID, features := range items {
        rs.AddItem(itemID, features)
    }
    
    // 用户偏好
    userPref := []float64{1, 0, 3, 0, 2} // 喜欢科技和教育类
    rs.AddUserPreference("user1", userPref)
    
    // 为用户推荐物品
    recommendations := rs.RecommendForUser("user1", 3)
    fmt.Println("用户1的推荐物品:")
    for _, rec := range recommendations {
        fmt.Printf("  物品%s: 相似度=%.3f\n", rec["item_id"], rec["similarity"])
    }
    
    // 查找相似物品
    fmt.Println("\n与物品1相似的物品:")
    similarItems := rs.FindSimilarItems("item1", 3)
    for _, item := range similarItems {
        fmt.Printf("  物品%s: 相似度=%.3f\n", item["item_id"], item["similarity"])
    }
    
    // 协同过滤示例
    fmt.Println("\n=== 协同过滤示例 ===")
    
    // 添加更多用户
    rs.AddUserPreference("user2", []float64{0, 1, 0, 3, 2})
    rs.AddUserPreference("user3", []float64{2, 1, 2, 1, 1})
    rs.AddUserPreference("user4", []float64{1, 0, 2, 0, 3})
    
    collabRecs := rs.CollaborativeFiltering("user1", 3)
    fmt.Println("基于用户的协同过滤推荐:")
    for _, rec := range collabRecs {
        fmt.Printf("  物品%s: 得分=%.3f\n", rec["item_id"], rec["score"])
    }
    
    // TF-IDF示例
    fmt.Println("\n=== TF-IDF向量化示例 ===")
    documents := []string{
        "machine learning is fun",
        "artificial intelligence is amazing",
        "deep learning is a subset of machine learning",
        "computer science includes algorithms",
    }
    
    vectorizer := NewTFIDFVectorizer(documents)
    
    query := "machine learning algorithms"
    queryVector := vectorizer.Transform(query)
    
    fmt.Printf("查询: %s\n", query)
    fmt.Printf("TF-IDF向量维度: %d\n", len(queryVector))
    
    // 计算查询与每个文档的相似度
    for i, doc := range documents {
        docVector := vectorizer.Transform(doc)
        similarity := CosineSimilarity(queryVector, docVector)
        fmt.Printf("  文档%d相似度: %.3f - %s\n", i+1, similarity, doc)
    }
}
```

## 性能优化和高级用法

### 并发计算相似度
```go
package main

import (
    "fmt"
    "sync"
    "time"
)

// 并发相似度计算
type ConcurrentSimilarityCalculator struct {
    Algorithm func(string, string) float64
    Workers   int
}

func NewConcurrentSimilarityCalculator(workers int) *ConcurrentSimilarityCalculator {
    return &ConcurrentSimilarityCalculator{
        Workers: workers,
    }
}

func (csc *ConcurrentSimilarityCalculator) BatchCompare(base string, targets []string) []float64 {
    results := make([]float64, len(targets))
    
    var wg sync.WaitGroup
    semaphore := make(chan struct{}, csc.Workers) // 控制并发数
    
    for i, target := range targets {
        wg.Add(1)
        semaphore <- struct{}{}
        
        go func(idx int, t string) {
            defer wg.Done()
            defer func() { <-semaphore }()
            
            // 这里可以使用任何相似度算法
            if csc.Algorithm != nil {
                results[idx] = csc.Algorithm(base, t)
            } else {
                // 默认使用Jaro-Winkler
                results[idx] = jaroWinkler(base, t)
            }
        }(i, target)
    }
    
    wg.Wait()
    return results
}

// 简化版Jaro-Winkler实现
func jaroWinkler(s1, s2 string) float64 {
    // 简化实现，实际应使用完整算法
    if s1 == s2 {
        return 1.0
    }
    
    // 计算匹配字符数
    matches := 0
    maxDist := max(len(s1), len(s2))/2 - 1
    if maxDist < 0 {
        maxDist = 0
    }
    
    for i := 0; i < len(s1); i++ {
        for j := max(0, i-maxDist); j < min(len(s2), i+maxDist+1); j++ {
            if s1[i] == s2[j] {
                matches++
                break
            }
        }
    }
    
    if matches == 0 {
        return 0.0
    }
    
    // 计算换位数
    transpositions := 0
    j := 0
    for i := 0; i < len(s1); i++ {
        if s1[i] == s2[j] {
            j++
        } else {
            transpositions++
        }
    }
    transpositions /= 2
    
    // Jaro相似度
    m := float64(matches)
    jaro := (m/float64(len(s1)) + m/float64(len(s2)) + (m-float64(transpositions))/m) / 3.0
    
    // Winkler改进：前缀奖励
    prefix := 0
    for i := 0; i < min(len(s1), len(s2)); i++ {
        if s1[i] == s2[i] {
            prefix++
        } else {
            break
        }
    }
    
    prefix = min(prefix, 4)
    winklerBonus := 0.1 * float64(prefix) * (1.0 - jaro)
    
    return jaro + winklerBonus
}

func main() {
    // 性能测试
    base := "hello world"
    targets := make([]string, 10000)
    for i := range targets {
        targets[i] = fmt.Sprintf("hello world %d", i)
    }
    
    fmt.Println("=== 并发相似度计算性能测试 ===")
    
    // 单线程
    start := time.Now()
    for _, target := range targets {
        jaroWinkler(base, target)
    }
    fmt.Printf("单线程耗时: %v\n", time.Since(start))
    
    // 并发
    calculator := NewConcurrentSimilarityCalculator(10)
    start = time.Now()
    calculator.BatchCompare(base, targets)
    fmt.Printf("10并发耗时: %v\n", time.Since(start))
}
```

### 相似度缓存
```go
// 带缓存的相似度计算器
type CachedSimilarityCalculator struct {
    cache map[string]map[string]float64
    mu    sync.RWMutex
    algorithm func(string, string) float64
}

func NewCachedSimilarityCalculator(algorithm func(string, string) float64) *CachedSimilarityCalculator {
    return &CachedSimilarityCalculator{
        cache:    make(map[string]map[string]float64),
        algorithm: algorithm,
    }
}

func (csc *CachedSimilarityCalculator) GetSimilarity(s1, s2 string) float64 {
    // 生成缓存键（保证顺序）
    key1, key2 := s1, s2
    if s1 > s2 {
        key1, key2 = s2, s1
    }
    
    // 读缓存
    csc.mu.RLock()
    if inner, ok := csc.cache[key1]; ok {
        if similarity, ok := inner[key2]; ok {
            csc.mu.RUnlock()
            return similarity
        }
    }
    csc.mu.RUnlock()
    
    // 计算相似度
    similarity := csc.algorithm(s1, s2)
    
    // 写缓存
    csc.mu.Lock()
    if _, ok := csc.cache[key1]; !ok {
        csc.cache[key1] = make(map[string]float64)
    }
    csc.cache[key1][key2] = similarity
    csc.mu.Unlock()
    
    return similarity
}

// 使用示例
func main() {
    calculator := NewCachedSimilarityCalculator(jaroWinkler)
    
    // 第一次计算
    start := time.Now()
    sim1 := calculator.GetSimilarity("hello", "hello")
    fmt.Printf("第一次计算耗时: %v, 结果: %.3f\n", time.Since(start), sim1)
    
    // 第二次计算（从缓存读取）
    start = time.Now()
    sim2 := calculator.GetSimilarity("hello", "hello")
    fmt.Printf("第二次计算耗时: %v, 结果: %.3f\n", time.Since(start), sim2)
}
```
